{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeXgStKvCGGx",
        "outputId": "5e35fc6d-521f-4e2d-956e-f270be9d8c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: audplot\n",
            "Successfully installed audplot-1.4.7\n"
          ]
        }
      ],
      "source": [
        "# Librerias necesarias para el correcto funcionamiento\n",
        "!pip install audonnx\n",
        "!pip install audinterface\n",
        "!pip install audb\n",
        "!pip install audmetric\n",
        "!pip install opensmile\n",
        "!pip install audplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import audeer\n",
        "import audonnx\n",
        "import numpy as np\n",
        "import audinterface\n",
        "import audb\n",
        "import audformat\n",
        "import audmetric\n",
        "import pandas as pd\n",
        "import opensmile\n",
        "import audiofile\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Function to download and extract the model\n",
        "def download_and_extract_model(model_url, dst_path, model_root, cache_root):\n",
        "    if not os.path.exists(dst_path):\n",
        "        audeer.download_url(\n",
        "            model_url,\n",
        "            dst_path,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "    if not os.path.exists(model_root):\n",
        "        audeer.extract_archive(\n",
        "            dst_path,\n",
        "            model_root,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model_root):\n",
        "    model = audonnx.load(model_root)\n",
        "    return model\n",
        "\n",
        "# Function to load the Emo-DB database\n",
        "def load_emodb_database(cache_root):\n",
        "    db = audb.load(\n",
        "        'emodb',\n",
        "        version='1.1.1',\n",
        "        format='wav',\n",
        "        mixdown=True,\n",
        "        sampling_rate=16000,\n",
        "        full_path=False,\n",
        "        cache_root=cache_root,\n",
        "        verbose=True,\n",
        "    )\n",
        "    return db\n",
        "\n",
        "# Function to perform leave-one-speaker-out cross-validation experiment\n",
        "def leave_one_speaker_out_experiment(features, targets, groups, clf):\n",
        "    truths = []\n",
        "    preds = []\n",
        "\n",
        "    logo = LeaveOneGroupOut()\n",
        "\n",
        "    pbar = audeer.progress_bar(\n",
        "        total=len(groups.unique()),\n",
        "        desc='Run experiment',\n",
        "    )\n",
        "    for train_index, test_index in logo.split(\n",
        "        features,\n",
        "        targets,\n",
        "        groups=groups,\n",
        "    ):\n",
        "        train_x = features.iloc[train_index]\n",
        "        train_y = targets[train_index]\n",
        "        clf.fit(train_x, train_y)\n",
        "\n",
        "        truth_x = features.iloc[test_index]\n",
        "        truth_y = targets[test_index]\n",
        "        predict_y = clf.predict(truth_x)\n",
        "\n",
        "        truths.append(truth_y)\n",
        "        preds.append(predict_y)\n",
        "\n",
        "        pbar.update()\n",
        "\n",
        "    truth = pd.concat(truths)\n",
        "    truth.name = 'truth'\n",
        "    pred = pd.Series(\n",
        "        np.concatenate(preds),\n",
        "        index=truth.index,\n",
        "        name='prediction',\n",
        "    )\n",
        "\n",
        "    return truth, pred\n",
        "\n",
        "# Function to process audio features using OpenSMILE\n",
        "def process_features(audio:str):\n",
        "    signal, sampling_rate = audiofile.read(audio)\n",
        "\n",
        "    smile = opensmile.Smile(\n",
        "        opensmile.FeatureSet.ComParE_2016,\n",
        "        opensmile.FeatureLevel.Functionals,\n",
        "        sampling_rate=16000,\n",
        "        resample=True,\n",
        "        num_workers=5,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    features = smile.process_signal(signal, sampling_rate)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Function to predict emotion from audio features\n",
        "def predict_emotion(features, clf):\n",
        "    predicted_emotion = clf.predict(features)\n",
        "    return predicted_emotion\n",
        "\n",
        "def main():\n",
        "    def cache_path(file):\n",
        "        # Check if the folder doesn't exist already, then create it\n",
        "        if not os.path.exists(cache_root):\n",
        "            os.makedirs(cache_root)\n",
        "        else:\n",
        "            print(f\"Folder '{cache_root}' already exists.\")\n",
        "\n",
        "        return os.path.join(cache_root, file)\n",
        "\n",
        "    model_root = 'model'\n",
        "    cache_root = 'cache'\n",
        "\n",
        "    dst_path = cache_path('model.zip')\n",
        "    model_url = 'https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip'\n",
        "\n",
        "    download_and_extract_model(model_url, dst_path, model_root, cache_root)\n",
        "\n",
        "    model = load_model(model_root)\n",
        "    db = load_emodb_database(cache_root)\n",
        "\n",
        "    speaker = db['files']['speaker'].get()\n",
        "    emotion = db['emotion']['emotion'].get()\n",
        "\n",
        "    audformat.utils.concat([emotion, speaker])\n",
        "\n",
        "    clf = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        SVC(gamma='auto'),\n",
        "    )\n",
        "\n",
        "    base = os.path.abspath('')\n",
        "    file_paths = glob(f\"{base}/*.WAV\")\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        features = process_features(file_path)\n",
        "        predicted_emotion = predict_emotion(features, clf)\n",
        "        print(\"Predicted Emotion:\", predicted_emotion)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"End\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lyjYqcjrCMCE",
        "outputId": "4482b0e4-56df-4553-92b6-a82dacff38e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'cache' already exists.\n",
            "Get:   emodb v1.1.1\n",
            "Cache: /content/cache/emodb/1.1.1/fe182b91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-06841a015983>\u001b[0m in \u001b[0;36m<cell line: 154>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-06841a015983>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mpredicted_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Emotion:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_emotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-06841a015983>\u001b[0m in \u001b[0;36mpredict_emotion\u001b[0;34m(features, clf)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Function to predict emotion from audio features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mpredicted_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_emotion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \"\"\"\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    }
  ]
}
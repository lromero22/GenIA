{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pK4gzt21nta"
      },
      "outputs": [],
      "source": [
        "!pip install pyannote.audio\n",
        "!pip install accelerate\n",
        "!pip install pydub\n",
        "!pip install whisper-timestamped"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker diarization"
      ],
      "metadata": {
        "id": "jy_7wfiC6ehM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pyannote.audio import Pipeline\n",
        "from pydub import AudioSegment\n",
        "import datetime\n",
        "import whisper_timestamped as whisper\n",
        "import time\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZkGsqsC1ueA",
        "outputId": "c1e0fcaf-9406-449b-c828-75cf4b743370"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el modelo de diarización de pyannote\n",
        "diarization_pipeline = Pipeline.from_pretrained(\n",
        "\"pyannote/speaker-diarization-3.1\",\n",
        "use_auth_token=\"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\")\n",
        "diarization_pipeline.to(torch.device(\"cuda\"))\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = whisper.load_model(\"large-v3\", device=device)\n"
      ],
      "metadata": {
        "id": "gU2TcTEq2DGk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def conversion_diarizacion_transcripcion(input_file,model,nombre_salida):\n",
        "  conversiones = [\n",
        "      (\"output_wav_pcm.wav\", \"pcm_s16le\", None)       # WAV sin compresión\n",
        "  ]\n",
        "\n",
        "  def format_time(seconds):\n",
        "    \"\"\" Convertir segundos a formato de tiempo HH:MM:SS \"\"\"\n",
        "    return str(datetime.timedelta(seconds=int(seconds)))\n",
        "\n",
        "\n",
        "  for output_file, codec, bitrate in conversiones:\n",
        "      if bitrate:\n",
        "          # Comando para conversiones con bitrate específico\n",
        "          command = f\"ffmpeg -i {input_file} -acodec {codec} -ar 44100 -b:a {bitrate} {output_file}\"\n",
        "      else:\n",
        "          # Comando para conversiones sin bitrate específico (sin pérdida)\n",
        "          command = f\"ffmpeg -i {input_file} -acodec {codec} -ar 44100 {output_file}\"\n",
        "      os.system(command)\n",
        "      print(f\"Archivo {output_file} creado.\")\n",
        "\n",
        "\n",
        "\n",
        "    # Ejecutar diarización\n",
        "  inicio_diarizacion = time.time()\n",
        "\n",
        "  diarization = diarization_pipeline(\"output_wav_pcm.wav\", num_speakers=2)\n",
        "  final_diarizacion = time.time()\n",
        "\n",
        "  tiempo_diarizacion=final_diarizacion-inicio_diarizacion\n",
        "\n",
        "\n",
        "  # Cargar y configurar el modelo de Whisper para el archivo completo\n",
        "  inicio_transcripcion = time.time()\n",
        "\n",
        "  audio = whisper.load_audio(\"output_wav_pcm.wav\")\n",
        "  transcription_result = whisper.transcribe(model, \"output_wav_pcm.wav\", language=\"es\", vad=True,detect_disfluencies=True,\n",
        "                                               beam_size=5, best_of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0))\n",
        "  final_transcripcion = time.time()\n",
        "\n",
        "  tiempo_transcripcion=final_transcripcion-inicio_transcripcion\n",
        "\n",
        "\n",
        "\n",
        "    # Preparar el archivo de salida y procesar la diarización y transcripción\n",
        "  with open(f\"{nombre_salida}.txt\", \"w\", encoding='utf-8') as output_file:\n",
        "        last_speaker = None\n",
        "        last_start = 0\n",
        "        last_end = 0\n",
        "        last_transcription = \"\"\n",
        "        total_confidence = 0\n",
        "        segments = transcription_result['segments']\n",
        "\n",
        "        for i, segment in enumerate(segments):\n",
        "            start_time = segment['start']\n",
        "            end_time = segment['end']\n",
        "            transcript_text = segment['text'].strip()\n",
        "            segment_confidence = segment['confidence']\n",
        "            total_confidence += segment_confidence\n",
        "\n",
        "            # Buscar el hablante que más se solapa con este segmento\n",
        "            speaker_label = None\n",
        "            max_overlap = 0\n",
        "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "                overlap = min(end_time, turn.end) - max(start_time, turn.start)\n",
        "                if overlap > max_overlap:\n",
        "                    max_overlap = overlap\n",
        "                    speaker_label = speaker\n",
        "\n",
        "            # Si no hay hablante identificado y estamos en el primer o último segmento, asignamos el último o el primer hablante conocido\n",
        "            if not speaker_label:\n",
        "                if i == 0:\n",
        "                    speaker_label = last_speaker  # Use the last known speaker for the first segment if none identified\n",
        "                elif i == len(segments) - 1:\n",
        "                    speaker_label = last_speaker  # Use the last known speaker for the last segment if none identified\n",
        "\n",
        "            # Combinar segmentos si el hablante es el mismo y no hay pausa significativa\n",
        "            if speaker_label == last_speaker and (start_time - last_end) < 1:\n",
        "                last_end = end_time\n",
        "                last_transcription += \" \" + transcript_text\n",
        "            else:\n",
        "                if last_speaker is not None:\n",
        "                    # Escribir el segmento previo\n",
        "                    output_file.write(f\"{format_time(last_start)} - {format_time(last_end)} [{last_speaker}]: {last_transcription}\\n\")\n",
        "                last_speaker = speaker_label\n",
        "                last_start = start_time\n",
        "                last_end = end_time\n",
        "                last_transcription = transcript_text\n",
        "        # Calcular y mostrar la confianza promedio por segmento para toda la transcripción\n",
        "        average_confidence = total_confidence /  len(transcription_result['segments']) if transcription_result['segments'] else 0\n",
        "        print(f\"Diarization and transcription completed. Average segment confidence: {average_confidence:.2f}\")\n",
        "\n",
        "        del diarization\n",
        "        del audio\n",
        "        del transcription_result\n",
        "        del output_file\n",
        "        gc.collect()\n",
        "\n",
        "  return(average_confidence,tiempo_diarizacion,tiempo_transcripcion)"
      ],
      "metadata": {
        "id": "MxKomSpq2DwU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OS BASED PATH\n",
        "# base = Path(__file__).resolve().parent\n",
        "# Notebook Path\n",
        "base = os.path.abspath('')\n",
        "\n",
        "audio_path = os.path.join(base, \"14838701_2.WAV\")\n",
        "transcribe_path = os.path.join(base, \"transcribe.txt\")\n",
        "\n",
        "input_file = \"14838701_2.WAV\"\n",
        "nombre_salida = \"transcribe\"\n",
        "\n",
        "average_confidence,tiempo_diarizacion,tiempo_transcripcion = conversion_diarizacion_transcripcion(input_file,model,nombre_salida)\n",
        "print(average_confidence)\n",
        "print(tiempo_diarizacion)\n",
        "print(tiempo_transcripcion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b5hcPb44XM-",
        "outputId": "091cd33d-2019-442c-dc50-f93a08eb1ad4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo output_wav_pcm.wav creado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:whisper_timestamped:Please install onnxruntime to use more efficiently silero VAD\n",
            "100%|██████████| 7108/7108 [00:23<00:00, 296.78frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diarization and transcription completed. Average segment confidence: 0.46\n",
            "0.4641363636363636\n",
            "12.728769540786743\n",
            "50.675360679626465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keyword find"
      ],
      "metadata": {
        "id": "VzSyjSst2veH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preproceso para unir, todos los textos de un speaker"
      ],
      "metadata": {
        "id": "ZAT2QXrT22M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open(\"transcribe.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
        "    transcribe = f.readlines()\n",
        "\n",
        "# Keyword preprocessing\n",
        "speaker1 = [line for line in transcribe if \"SPEAKER_00\" in line]\n",
        "speaker2 = [line for line in transcribe if \"SPEAKER_01\" in line]\n",
        "\n",
        "# Join the lines of each speaker\n",
        "speaker1 = \" \".join(speaker1)\n",
        "speaker2 = \" \".join(speaker2)\n",
        "\n",
        "# Remove the strings that match the pattern 00:00:00 - 0:00:26 [SPEAKER_00]:\n",
        "pattern = r\"\\d{1,2}:\\d{2}:\\d{2} - \\d{1,2}:\\d{2}:\\d{2} \\[SPEAKER_\\d{2}\\]:\"\n",
        "\n",
        "speaker1 = re.sub(pattern, \"\", speaker1)\n",
        "speaker2 = re.sub(pattern, \"\", speaker2)\n",
        "\n",
        "speaker1 = speaker1.split(\"\\n\")\n",
        "speaker2 = speaker2.split(\"\\n\")"
      ],
      "metadata": {
        "id": "MiJA7aAQ21eF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keyword find per item"
      ],
      "metadata": {
        "id": "8AoY2MREAafk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load spanish pipeline"
      ],
      "metadata": {
        "id": "hEV51L56CKUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_lg\n",
        "# !python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "id": "5AOi4WvTMPZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "spanish_nlp = spacy.load(\"es_core_news_lg\")\n",
        "nlp = spacy.blank(\"es\", vocab=spanish_nlp.vocab)\n",
        "\n",
        "#use spacy in each item of the speaker list\n",
        "speaker1 = [nlp(line) for line in speaker1]\n",
        "speaker2 = [nlp(line) for line in speaker2]\n",
        "\n",
        "# Find type of conversation using spacy\n",
        "# Find the most common entity in the conversation\n",
        "speaker1_entities = [ent.label_ for line in speaker1 for ent in line.ents]\n",
        "speaker2_entities = [ent.label_ for line in speaker2 for ent in line.ents]\n",
        "\n",
        "print(speaker1_entities)\n",
        "print(speaker2_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1xBHV_L2z7t",
        "outputId": "90577e2b-f37d-4d3a-f21c-901dc7d9676d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PER', 'PER', 'PER', 'PER', 'PER', 'LOC', 'ORG', 'MISC', 'PER']\n",
            "['LOC', 'PER', 'PER', 'PER', 'LOC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.serve(speaker1[5], style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "tu7ebuPmIQ5a",
        "outputId": "202901c1-5e6f-42c5-eaf1-1aa35f331d77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">  Ah, bueno, perfecto Entonces, pues la idea es que era confirmar que la evidencia de tu póliza quedó desde el 23 de marzo del 2024 \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ¿Para qué\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " le pasó? Que desde ese día está protegida tu mundo visto \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Visto de una Muchas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " gracias \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Alejandro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", un excelente trabajo</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensayo inicial de modelos de reconocimiento de voz usando IA whisper de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando la IA para hacer transcripts\n",
    "import whisper \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Όταν γυρίσαμε το βράδυ στο δωμάτιο βρήκαμε στο κρεβάτι δύο μικρά γατάκια.\n"
     ]
    }
   ],
   "source": [
    "# Prueba simple de whisper\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(\"ActedEmotionalSpeechDynamicDatabase/anger/a01 (1).wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl = whisper.load_model(\"tiny\")\n",
    "translation = model.transcribe(audio=\"ActedEmotionalSpeechDynamicDatabase/anger/a01 (1).wav\", task = 'translate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Όταν γυρίσαμε το βράδυ στο δωμάτιο βρήκαμε στο κρεβάτι δύο μικρά γατάκια.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 4.16, 'text': ' Όταν γυρίσαμε το βράδυ στο δωμάτιο βρήκαμε στο κρεβάτι δύο μικρά γατάκια.', 'tokens': [50364, 43692, 26263, 10643, 3226, 24296, 23791, 9104, 8335, 15787, 17750, 8385, 3226, 20702, 8715, 5733, 34079, 13580, 1800, 15787, 2805, 7068, 31714, 9104, 20702, 4903, 27672, 14836, 3849, 13580, 8715, 6956, 1800, 5337, 10073, 17750, 10643, 1529, 19389, 4915, 8311, 13, 50572], 'temperature': 0.0, 'avg_logprob': -0.10868958993391557, 'compression_ratio': 1.4105263157894736, 'no_speech_prob': 0.008845404721796513}], 'language': 'el'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' When we returned to the room at night, we found two small cats in the bed.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result)\n",
    "translation[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: el\n",
      "Όταν γυρίσαμε το βράδει στο δομμάτιο, βρήκαμε στο κρεβάτι, βίω μικρά γατάκια.\n"
     ]
    }
   ],
   "source": [
    "# Prueba para detectar el lenguaje\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"ActedEmotionalSpeechDynamicDatabase/anger/a01 (1).wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensayando con otra base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' But in less than five minutes the staircase groaned beneath an extraordinary weight.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura del audio\n",
    "audio = whisper.load_audio(\"LibriSpeech/dev-clean/84/121123/84-121123-0001.flac\")\n",
    "mod_prueba = whisper.load_model(\"medium\")\n",
    "result_prueba = mod_prueba.transcribe(audio = audio)\n",
    "result_prueba[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemene, la eficiencia de la transcripción mejora con el formato del audio (la base de datos con FLAC fue transcrita mucho más \n",
    "rápida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' But in less than five minutes the staircase groaned beneath an extraordinary weight.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando pruebas con os para acceder carpetas y archivos\n",
    "# Definiendo al path de los archivos\n",
    "files_folder = os.getcwd() + \"\\\\LibriSpeech\\\\dev-clean\\\\84\\\\121123\\\\\"\n",
    "\n",
    "aux = whisper.load_audio(files_folder + \"84-121123-0001.flac\")\n",
    "mod_prueba = whisper.load_model(\"medium\")\n",
    "result_prueba = mod_prueba.transcribe(audio = audio)\n",
    "result_prueba[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.txt'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(file)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Go! Do you hear?\n",
      " But in less than five minutes, the staircase groaned beneath an extraordinary weight.\n",
      " At this moment, the whole soul of the old man seemed centered in his eyes which became bloodshot. The veins of the throat swelled. His cheeks and temples became purple as though he was struck with epilepsy. Nothing was wanting to complete this but the utterance of a cry.\n",
      " and the cry issued from his pores if we may thus speak a cry frightful in its silence.\n",
      " Devani rushed towards the old man and made him inhale a powerful restorative.\n",
      " Davani, unable to bear the sight of this touching emotion, turned away, and Villafort, without seeking any further explanation, and attracted towards him by the irresistible magnetism which draws us towards those who have loved the people for whom we mourn, extended his hand towards the young man.\n",
      " For some time, nothing was heard in that chamber, but sobbs, exclamation and prayers.\n",
      " What do you mean, sir?\n",
      " Oh, you rave, sir! Exclaimed Villifort, in vain, endeavoring to escape the net in which he was taken. I rave!\n",
      " Do you know the assassin? Esmeral.\n",
      " Nautier looked upon morale with one of those melancholy smiles which had so often made Valentine happy and thus fixed his attention.\n",
      " said morale sadly. Yes, replied no to A.\n",
      " The old man's eyes remain fixed on the door.\n",
      " as morale. Yes.\n",
      " Must I leave alone? No.\n",
      " But can he understand you? Yes.\n",
      " Gentlemen, he said in a horse voice, give me your word of honor that this horrible secret shell forever remained buried amongst ourselves. The two men drew back.\n",
      " My father has revealed the culprit's name. My father thirsts for revenge as much as you do, yet even he conjures you as I do to keep this secret. Do you not, father?\n",
      " Morrell suffered an exclamation of horror and surprised to escape him.\n",
      " The old man made a sign in the affirmative.\n",
      " It was something terrible to witness the silent agony, the mute despair of Nautier whose tears silently rolled on his cheeks.\n",
      " But he stopped on the landing. He had not the courage to again visit the death chamber.\n",
      " The two doctors therefore entered the room alone.\n",
      " Nwatiya was near the bed, pale, motionless, and silent as the corpse.\n",
      " The district doctor approached with the indifference of a man accustomed to spend half his time amongst the dead. He then lifted the sheet, which was placed over the face, and just unclosed to the lips.\n",
      " The nearest, said the district doctor, is a good Italian abay who lives next door to you. Shall I call on him as I pass?\n",
      " Daverne said Willefort. Be so kind I would see to you as to accompany this gentleman. Here is the key of the door so that you can go in and out as you please. You will bring the priest with you and will oblige me by introducing him into my child's room. Do you wish to see him?\n",
      " I only wish to be alone. You will excuse me, will you not?\n",
      " I am going, sir, and I do not hesitate to say that no prayers will be more fervent than mine.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio: ffmpeg version 6.1.1-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\r\n  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --pkg-config=pkgconf --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      58. 29.100 / 58. 29.100\r\n  libavcodec     60. 31.102 / 60. 31.102\r\n  libavformat    60. 16.100 / 60. 16.100\r\n  libavdevice    60.  3.100 / 60.  3.100\r\n  libavfilter     9. 12.100 /  9. 12.100\r\n  libswscale      7.  5.100 /  7.  5.100\r\n  libswresample   4. 12.100 /  4. 12.100\r\n  libpostproc    57.  3.100 / 57.  3.100\r\nInput #0, tty, from 'c:\\Users\\usuario\\Documents\\LikeU\\SpeechToText\\LibriSpeech\\dev-clean\\84\\121123\\84-121123.trans.txt':\r\n  Duration: 00:00:00.56, start: 0.000000, bitrate: 46 kb/s\r\n  Stream #0:0: Video: ansi, pal8, 640x400, 25 fps, 25 tbr, 25 tbn\r\nOutput #0, s16le, to 'pipe:':\r\n[out#0/s16le @ 000001d36560d3c0] Output file does not contain any stream\r\nError opening output file -.\r\nError opening output files: Invalid argument\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'c:\\\\Users\\\\usuario\\\\Documents\\\\LikeU\\\\SpeechToText\\\\LibriSpeech\\\\dev-clean\\\\84\\\\121123\\\\84-121123.trans.txt', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 4294967274.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(files_folder):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitdrive(file)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m         current_transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfiles_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(current_transcription[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:122\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    119\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\audio.py:60\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     58\u001b[0m     out \u001b[38;5;241m=\u001b[39m run(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(out, np\u001b[38;5;241m.\u001b[39mint16)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32768.0\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 6.1.1-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\r\n  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --pkg-config=pkgconf --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      58. 29.100 / 58. 29.100\r\n  libavcodec     60. 31.102 / 60. 31.102\r\n  libavformat    60. 16.100 / 60. 16.100\r\n  libavdevice    60.  3.100 / 60.  3.100\r\n  libavfilter     9. 12.100 /  9. 12.100\r\n  libswscale      7.  5.100 /  7.  5.100\r\n  libswresample   4. 12.100 /  4. 12.100\r\n  libpostproc    57.  3.100 / 57.  3.100\r\nInput #0, tty, from 'c:\\Users\\usuario\\Documents\\LikeU\\SpeechToText\\LibriSpeech\\dev-clean\\84\\121123\\84-121123.trans.txt':\r\n  Duration: 00:00:00.56, start: 0.000000, bitrate: 46 kb/s\r\n  Stream #0:0: Video: ansi, pal8, 640x400, 25 fps, 25 tbr, 25 tbn\r\nOutput #0, s16le, to 'pipe:':\r\n[out#0/s16le @ 000001d36560d3c0] Output file does not contain any stream\r\nError opening output file -.\r\nError opening output files: Invalid argument\r\n"
     ]
    }
   ],
   "source": [
    "#Prueba transcribiendo todos los audios del libro de forma completa\n",
    "# Definiendo al path de los archivos\n",
    "files_folder = os.getcwd() + \"\\\\LibriSpeech\\\\dev-clean\\\\84\\\\121123\\\\\"\n",
    "\n",
    "# IA para realizar las transcripciones\n",
    "transcribe = whisper.load_model(\"base\")\n",
    "\n",
    "# Archivos sobre los cuales se va a realizar transcripciones\n",
    "for file in os.listdir(files_folder):\n",
    "    if os.path.splitdrive(file)[-1] != \".txt\":\n",
    "        current_transcription = transcribe.transcribe(audio = files_folder + file)\n",
    "        print(current_transcription[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con un audio real de LikeU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [12:39<00:00, 4.07MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Aló. Aló, buenas tardes. Me vuelvo a hablar con el señor Alejandro. ¿Con él habla? Con Natalia Montoya de Sudamericana. ¿Cómo has estado? ¿De dónde, perdón? Natalia Montoya de Sudamericana. Hola, Natalia, ¿cómo estás? Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela. Sí, está quedando la píxel igual mismo día que hablamos. ¿Cómo? ¿Llegó el mismo día? Sí, llegó el mismo día. Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar que el principio de evidencia de tu póliza quedó desde el 23 de marzo del 2024 para que sepas que desde ese día está protegida tu módulo de visto. Visto de una. Muchas gracias, Alejandro. Una excelente tarde. Dale, con gusto, gracias. Que estés bien, hasta luego. Chao.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = whisper.load_audio(\"14838701_2.WAV\")\n",
    "mod_likeu = whisper.load_model(\"large\")\n",
    "result_likeu = mod_likeu.transcribe(audio = aux)\n",
    "result_likeu[\"text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

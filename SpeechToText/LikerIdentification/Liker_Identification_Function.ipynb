{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función final para identificación del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacionde requerimientos en caso de ser necesario\n",
    "# pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias necesarias\n",
    "# Importacion de librerias\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Carga del modelo\n",
    "spacy.require_cpu() # Temporal mientras se arregla problema con uso de GPU\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función ya trae por defecto un conjunto de patrones para identificar el Liker pero solo es válido para la campaña de SURA\n",
    "def Speaker_Asignation(file_path, additional_patterns = [], write_txt = True, keep_strategies = True, Word_Count = False, Num_Matches = False, install_requirements = False):\n",
    "    \"\"\"\n",
    "    file_path: path of the transcripted .txt file without the Speaker asignation (i.e each file has either SPEAKER_00 or SPEAKER_01)\n",
    "    write_txt: Specify if you want to create a new .txt file with the asigned roles by the function\n",
    "    additional_patterns: List or dict. Additional patterns to be used in the third strategy (those one not considered or belong to other campaign).\n",
    "    keep_strategies: Include columns of the asigned role in each strategy\n",
    "    Word_Count: Include the number of words spoken by speaker in each line\n",
    "    Num_Matches: Include the number of matches in the considered patterns to search\n",
    "    \"\"\"\n",
    "    # Lectura del archivo de transcripcion\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as archivo:\n",
    "        aux_list_df = [] # Lista auxiliar para creacion del df\n",
    "        # Itera sobre cada línea del archivo\n",
    "        for linea in archivo:\n",
    "            # Creacion del dataframe con la transcripcion\n",
    "            transcript = [linea[:17].strip(), linea[19:29].strip(), linea[31:].strip()]\n",
    "            aux_list_df.append(transcript)\n",
    "            \n",
    "        # Creacion del dataframe con la transcripcion\n",
    "        transcript_df = pd.DataFrame(aux_list_df, columns = [\"Tiempo\", \"Speaker\", \"Texto\"])\n",
    "    \n",
    "    # Solucion 1: Liker = Primer speaker\n",
    "    transcript_df[\"Speaker_Asignado_Opt_1\"] = np.where(transcript_df.Speaker == transcript_df.Speaker[0], \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Solucion 2: Liker =  Persona que mas habla\n",
    "    transcript_df[\"Word_Count\"] = transcript_df.Texto.apply(lambda x: len(x.split())) # Columna auxiliar para contar el numero de palabras en cada fila\n",
    "\n",
    "    # Group by para identificar el Speaker que más habla\n",
    "    words_per_speaker = transcript_df[[\"Speaker\", \"Word_Count\"]].groupby(by = \"Speaker\").sum().reset_index()\n",
    "\n",
    "    # Asignacion del speaker segun que tanto habla\n",
    "    # Lista booleana con el respectivo mapeo\n",
    "    mapping_opt_2 = [words_per_speaker[words_per_speaker.Word_Count == words_per_speaker.Word_Count.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "    transcript_df[\"Speaker_Asignado_Opt_2\"] = np.where(mapping_opt_2, \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Eliminacion de columna auxiliar (Eliminar linea de abajo en caso de querer conservarla)\n",
    "    if not Word_Count:\n",
    "        transcript_df.drop(columns = \"Word_Count\", inplace = True)\n",
    "\n",
    "    # Solucion 3: Conteo del numero de ocurrencias de patrones particulares\n",
    "    # Creacion del matcher para buscar patrones\n",
    "    matcher = Matcher(nlp.vocab) # Matcher\n",
    "    sura_patterns = [[{\"LOWER\": \"sudamericana\"}], [{\"LOWER\": \"de\"}, {\"LOWER\": \"sudamericana\"}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'sura'}}], [{\"LOWER\": \"de\"}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'seguro'}}], [{\"LOWER\": {\"REGEX\": r'seguro'}}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": \"póliza\"}], [{\"LOWER\": \"poliza\"}], [{\"LOWER\": {\"REGEX\": \"cotización\"}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'asegura'}}],\n",
    "                    [{\"LOWER\": \"grabada\"}], [{\"LOWER\": \"monitoreada\"}], [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}],\n",
    "                    [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}, {\"LOWER\": \"y\"}, {\"LOWER\": \"monitoreada\"}],\n",
    "                    [{\"LOWER\": \"validar\"}, {\"LOWER\": \"datos\"}]]\n",
    "    matcher.add(\"sura_patterns\", sura_patterns)\n",
    "    \n",
    "    # Agregacion de patrone adicionales dados por el usuario\n",
    "    if len(additional_patterns) != 0:\n",
    "        if isinstance(additional_patterns, list):\n",
    "            additional_patterns_lower = [token.lower() for token in additional_patterns]\n",
    "            patterns = [[{\"LOWER\": token} for token in item.split()] for item in additional_patterns_lower]\n",
    "            print(patterns)\n",
    "            matcher.add(\"additional_patterns\", patterns)\n",
    "        elif isinstance(additional_patterns, dict):\n",
    "             matcher.add(additional_patterns)\n",
    "\n",
    "    # Conteo de cuantos patrones encuentra por speaker\n",
    "    transcript_df[\"Num_Matches\"] = transcript_df.Texto.apply(lambda x: len(matcher(nlp(x))))\n",
    "\n",
    "    # Group by para identificar el Speaker que mas patrones repite\n",
    "    num_matches = transcript_df[[\"Speaker\", \"Num_Matches\"]].groupby(by = \"Speaker\").sum().reset_index()\n",
    "\n",
    "    # Asignacion del speaker segun numero de matches\n",
    "    # Lista booleana con el respectivo mapeo\n",
    "    mapping_opt_3 = [num_matches[num_matches.Num_Matches == num_matches.Num_Matches.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "    transcript_df[\"Speaker_Asignado_Opt_3\"] = np.where(mapping_opt_3, \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Eliminacion de columna auxiliar (Eliminar linea de abajo en caso de querer conservarla)\n",
    "    if not Num_Matches:\n",
    "        transcript_df.drop(columns = \"Num_Matches\", inplace = True)\n",
    "\n",
    "    # Asignacion final del speaker\n",
    "    bool_df = transcript_df[[\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"]].apply(lambda x: x == \"Liker\")\n",
    "    transcript_df[\"Speaker_Asignado\"] = np.where(np.sum(bool_df, axis = 1).between(2, 3), \"[Liker  ]:\", \"[Cliente]:\")\n",
    "    \n",
    "    # Elimnacion de columnas para asignacion final (en caso de requerirse)\n",
    "    if not keep_strategies:\n",
    "        transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"], inplace = True)\n",
    "\n",
    "    # Escribir la transcripción en un archivo txt\n",
    "    if write_txt:\n",
    "        # Lista para   \n",
    "        to_write_list = transcript_df[[\"Tiempo\", \"Speaker_Asignado\", \"Texto\"]].apply(lambda x: \" \".join(x.astype(str)), axis = 1)\n",
    "        # Abrir el archivo en modo de escritura\n",
    "        with open(\"Identified_Speakers\\\\\" + \"Asigned_Speaker_\" + os.path.basename(file_path), 'w') as archivo:\n",
    "            # Iterar sobre la lista y escribir cada texto en una nueva línea\n",
    "            for texto in to_write_list:\n",
    "                archivo.write(texto + '\\n')\n",
    "\n",
    "    # print(\"Los textos se han escrito en el archivo {}.\".format(nombre_archivo))\n",
    "    return {\"Transcripted_Df\": transcript_df, \"Word_Count\": words_per_speaker, \"Num_Matches\": num_matches}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignación de roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tiempo</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Speaker_Asignado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:00:10 - 0:00:10</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Hola</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0:00:11 - 0:00:13</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Sí, buenas tardes ¿Con Juan Cartagena?</td>\n",
       "      <td>[Liker  ]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0:00:14 - 0:00:15</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Sí</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0:00:16 - 0:00:18</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Hola, hola ¿Cómo estás?</td>\n",
       "      <td>[Liker  ]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0:00:19 - 0:00:20</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Muy bien</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0:09:43 - 0:09:44</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Listo. Listo.</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0:09:44 - 0:09:50</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Listo. Y dime, yo ya me comunicaría entonces c...</td>\n",
       "      <td>[Liker  ]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0:09:51 - 0:09:53</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Bueno. Listo. Hágale pues.</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0:09:53 - 0:09:56</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Bueno, Juan. Ustedes recuerden que hablaste co...</td>\n",
       "      <td>[Liker  ]:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0:09:57 - 0:09:58</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Listo. Gracias.</td>\n",
       "      <td>[Cliente]:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tiempo     Speaker  \\\n",
       "0   0:00:10 - 0:00:10  SPEAKER_01   \n",
       "1   0:00:11 - 0:00:13  SPEAKER_00   \n",
       "2   0:00:14 - 0:00:15  SPEAKER_01   \n",
       "3   0:00:16 - 0:00:18  SPEAKER_00   \n",
       "4   0:00:19 - 0:00:20  SPEAKER_01   \n",
       "..                ...         ...   \n",
       "80  0:09:43 - 0:09:44  SPEAKER_01   \n",
       "81  0:09:44 - 0:09:50  SPEAKER_00   \n",
       "82  0:09:51 - 0:09:53  SPEAKER_01   \n",
       "83  0:09:53 - 0:09:56  SPEAKER_00   \n",
       "84  0:09:57 - 0:09:58  SPEAKER_01   \n",
       "\n",
       "                                                Texto Speaker_Asignado  \n",
       "0                                                Hola       [Cliente]:  \n",
       "1              Sí, buenas tardes ¿Con Juan Cartagena?       [Liker  ]:  \n",
       "2                                                  Sí       [Cliente]:  \n",
       "3                             Hola, hola ¿Cómo estás?       [Liker  ]:  \n",
       "4                                            Muy bien       [Cliente]:  \n",
       "..                                                ...              ...  \n",
       "80                                      Listo. Listo.       [Cliente]:  \n",
       "81  Listo. Y dime, yo ya me comunicaría entonces c...       [Liker  ]:  \n",
       "82                         Bueno. Listo. Hágale pues.       [Cliente]:  \n",
       "83  Bueno, Juan. Ustedes recuerden que hablaste co...       [Liker  ]:  \n",
       "84                                    Listo. Gracias.       [Cliente]:  \n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Speaker_Asignation(\"Raw_Transcriptions/1001764369_1_transcription.txt\", write_txt=False, keep_strategies=False)[\"Transcripted_Df\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

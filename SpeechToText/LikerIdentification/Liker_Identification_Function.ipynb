{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función final para identificación del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacionde requerimientos en caso de ser necesario\n",
    "# pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias necesarias\n",
    "# Importacion de librerias\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Carga del modelo\n",
    "spacy.require_cpu() # Temporal mientras se arregla problema con uso de GPU\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función ya trae por defecto un conjunto de patrones para identificar el Liker pero solo es válido para la campaña de SURA\n",
    "def Speaker_Asignation(file_path, additional_patterns = [], write_txt = True, keep_strategies = True, Word_Count = False, Num_Matches = False, install_requirements = False):\n",
    "    \"\"\"\n",
    "    file_path: path of the transcripted .txt file without the Speaker asignation (i.e each file has either SPEAKER_00 or SPEAKER_01)\n",
    "    write_txt: Specify if you want to create a new .txt file with the asigned roles by the function\n",
    "    additional_patterns: List or dict. Additional patterns to be used in the third strategy (those one not considered or belong to other campaign).\n",
    "    keep_strategies: Include columns of the asigned role in each strategy\n",
    "    Word_Count: Include the number of words spoken by speaker in each line\n",
    "    Num_Matches: Include the number of matches in the considered patterns to search\n",
    "    \"\"\"\n",
    "    # Lectura del archivo de transcripcion\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as archivo:\n",
    "        aux_list_df = [] # Lista auxiliar para creacion del df\n",
    "        # Itera sobre cada línea del archivo\n",
    "        for linea in archivo:\n",
    "            # Creacion del dataframe con la transcripcion\n",
    "            transcript = [linea[:17].strip(), linea[19:29].strip(), linea[31:].strip()]\n",
    "            aux_list_df.append(transcript)\n",
    "            \n",
    "        # Creacion del dataframe con la transcripcion\n",
    "        transcript_df = pd.DataFrame(aux_list_df, columns = [\"Tiempo\", \"Speaker\", \"Texto\"])\n",
    "    \n",
    "    # Solucion 1: Liker = Primer speaker\n",
    "    transcript_df[\"Speaker_Asignado_Opt_1\"] = np.where(transcript_df.Speaker == transcript_df.Speaker[0], \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Solucion 2: Liker =  Persona que mas habla\n",
    "    transcript_df[\"Word_Count\"] = transcript_df.Texto.apply(lambda x: len(x.split())) # Columna auxiliar para contar el numero de palabras en cada fila\n",
    "\n",
    "    # Group by para identificar el Speaker que más habla\n",
    "    words_per_speaker = transcript_df[[\"Speaker\", \"Word_Count\"]].groupby(by = \"Speaker\").sum().reset_index()\n",
    "\n",
    "    # Asignacion del speaker segun que tanto habla\n",
    "    # Lista booleana con el respectivo mapeo\n",
    "    mapping_opt_2 = [words_per_speaker[words_per_speaker.Word_Count == words_per_speaker.Word_Count.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "    transcript_df[\"Speaker_Asignado_Opt_2\"] = np.where(mapping_opt_2, \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Eliminacion de columna auxiliar (Eliminar linea de abajo en caso de querer conservarla)\n",
    "    if not Word_Count:\n",
    "        transcript_df.drop(columns = \"Word_Count\", inplace = True)\n",
    "\n",
    "    # Solucion 3: Conteo del numero de ocurrencias de patrones particulares\n",
    "    # Creacion del matcher para buscar patrones\n",
    "    matcher = Matcher(nlp.vocab) # Matcher\n",
    "    sura_patterns = [[{\"LOWER\": \"sudamericana\"}], [{\"LOWER\": \"de\"}, {\"LOWER\": \"sudamericana\"}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'sura'}}], [{\"LOWER\": \"de\"}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'seguro'}}], [{\"LOWER\": {\"REGEX\": r'seguro'}}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": \"póliza\"}], [{\"LOWER\": \"poliza\"}], [{\"LOWER\": {\"REGEX\": \"cotización\"}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'asegura'}}],\n",
    "                    [{\"LOWER\": \"grabada\"}], [{\"LOWER\": \"monitoreada\"}], [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}],\n",
    "                    [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}, {\"LOWER\": \"y\"}, {\"LOWER\": \"monitoreada\"}],\n",
    "                    [{\"LOWER\": \"validar\"}, {\"LOWER\": \"datos\"}]]\n",
    "    matcher.add(\"sura_patterns\", sura_patterns)\n",
    "    \n",
    "    # Agregacion de patrone adicionales dados por el usuario\n",
    "    if len(additional_patterns) != 0:\n",
    "        if isinstance(additional_patterns, list):\n",
    "            additional_patterns_lower = [token.lower() for token in additional_patterns]\n",
    "            patterns = [[{\"LOWER\": token} for token in item.split()] for item in additional_patterns_lower]\n",
    "            matcher.add(\"additional_patterns\", patterns)\n",
    "        elif isinstance(additional_patterns, dict):\n",
    "             matcher.add(additional_patterns)\n",
    "\n",
    "    # Conteo de cuantos patrones encuentra por speaker\n",
    "    transcript_df[\"Num_Matches\"] = transcript_df.Texto.apply(lambda x: len(matcher(nlp(x))))\n",
    "\n",
    "    # Group by para identificar el Speaker que mas patrones repite\n",
    "    num_matches = transcript_df[[\"Speaker\", \"Num_Matches\"]].groupby(by = \"Speaker\").sum().reset_index().sort_values(\"Num_Matches\", ascending = False)\n",
    "    \n",
    "    # Verificar posible empate\n",
    "    tie = len(num_matches['Num_Matches'].unique()) == 1\n",
    "\n",
    "    if not tie:\n",
    "        # Asignacion del speaker segun numero de matches\n",
    "        # Lista booleana con el respectivo mapeo\n",
    "        mapping_opt_3 = [num_matches[num_matches.Num_Matches == num_matches.Num_Matches.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = np.where(mapping_opt_3, \"Liker\", \"Cliente\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = \"Empate\"\n",
    "\n",
    "    if not Num_Matches:\n",
    "            transcript_df.drop(columns = \"Num_Matches\", inplace = True)\n",
    "    \n",
    "    # SI HAY EMPATE, SE LE DA PRIORIDAD A LA SEGUNDA ESTRATEGGIA (PERSONA QUE MAS HABLA)\n",
    "    if not tie:\n",
    "        # Asignacion final del speaker\n",
    "        bool_df = transcript_df[[\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"]].apply(lambda x: x == \"Liker\")\n",
    "        transcript_df[\"Speaker_Asignado\"] = np.where(np.sum(bool_df, axis = 1).between(2, 3), \"[Liker  ]:\", \"[Cliente]:\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado\"] = transcript_df[\"Speaker_Asignado_Opt_2\"]    \n",
    "    \n",
    "    # Elimnacion de columnas para asignacion final (en caso de requerirse)\n",
    "    if not keep_strategies:\n",
    "        if not tie:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"], inplace = True)\n",
    "        else:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\"], inplace = True)\n",
    "            \n",
    "    # Escribir la transcripción en un archivo txt\n",
    "    if write_txt:\n",
    "        # Lista para   \n",
    "        to_write_list = transcript_df[[\"Tiempo\", \"Speaker_Asignado\", \"Texto\"]].apply(lambda x: \" \".join(x.astype(str)), axis = 1)\n",
    "        # Abrir el archivo en modo de escritura\n",
    "        with open(\"Identified_Speakers\\\\\" + \"Asigned_Speaker_\" + os.path.basename(file_path), 'w') as archivo:\n",
    "            # Iterar sobre la lista y escribir cada texto en una nueva línea\n",
    "            for texto in to_write_list:\n",
    "                archivo.write(texto + '\\n')\n",
    "\n",
    "    return {\"Transcripted_Df\": transcript_df, \"Word_Count\": words_per_speaker, \"Num_Matches\": num_matches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001764369_1_transcription.txt',\n",
       " '1014249230_3_transcription.txt',\n",
       " '1129574339_6_transcription.txt',\n",
       " '14838701_2_transcription.txt',\n",
       " 'force-44441940-972-20240401-112258-1711988578.150759.txt',\n",
       " 'out-3003958667-994-20240405-163905-1712353145.162469.txt',\n",
       " 'out-3054535186-936-20240401-115437-1711990477.150948.txt',\n",
       " 'out-3103166473-973-20240404-180947-1712272187.160933.txt',\n",
       " 'out-3103465155-956-20240401-132257-1711995777.151309.txt',\n",
       " 'out-3103675012-936-20240404-095452-1712242492.158691.txt',\n",
       " 'out-3103723286-956-20240405-135755-1712343475.161940.txt',\n",
       " 'out-3103814989-913-20240404-161134-1712265094.160513.txt',\n",
       " 'out-3103814989-913-20240405-175919-1712357959.162644.txt',\n",
       " 'out-3103894985-900-20240405-151650-1712348210.162208.txt',\n",
       " 'out-3104294636-980-20240403-162248-1712179368.157746.txt',\n",
       " 'out-3104493260-900-20240402-181030-1712099430.155354.txt',\n",
       " 'out-3104560865-913-20240405-084247-1712324567.161074.txt',\n",
       " 'out-3104875598-900-20240402-141516-1712085316.154263.txt',\n",
       " 'out-3118642729-913-20240405-141059-1712344259.161987.txt',\n",
       " 'out-3125537410-940-20240403-173114-1712183474.158137.txt',\n",
       " 'out-3126588650-966-20240403-175943-1712185183.158207.txt',\n",
       " 'out-3126741945-900-20240404-114213-1712248933.159343.txt',\n",
       " 'out-3145275830-973-20240404-092836-1712240916.158545.txt',\n",
       " 'out-3164213703-913-20240405-104154-1712331714.161339.txt',\n",
       " 'out-3165237464-993-20240405-153645-1712349405.162287.txt',\n",
       " 'out-3167563398-973-20240405-101001-1712329801.161196.txt',\n",
       " 'out-3167682022-993-20240405-114056-1712335256.161634.txt',\n",
       " 'out-3187049147-993-20240401-085542-1711979742.149987.txt',\n",
       " 'out-3193186167-900-20240405-171830-1712355510.162579.txt',\n",
       " 'out-3193186167-900-20240405-172453-1712355893.162589.txt',\n",
       " 'out-3195989894-919-20240401-105207-1711986727.150627.txt',\n",
       " 'out-3202023245-900-20240405-143756-1712345876.162067.txt',\n",
       " 'out-3202776577-966-20240403-081925-1712150365.155641.txt',\n",
       " 'out-3205140598-900-20240405-170331-1712354611.162528.txt',\n",
       " 'out-3205181563-966-20240405-123215-1712338335.161779.txt',\n",
       " 'out-3206151227-940-20240403-153302-1712176382.157436.txt',\n",
       " 'out-3213432785-996-20240401-181641-1712013401.152483.txt',\n",
       " 'out-3215088513-980-20240405-143804-1712345884.162069.txt',\n",
       " 'out-3222529193-998-20240405-142201-1712344921.162016.txt',\n",
       " 'out-3222529193-998-20240405-142814-1712345294.162035.txt',\n",
       " 'out-3225954911-934-20240405-144834-1712346514.162097.txt',\n",
       " 'out-3239315555-956-20240404-112734-1712248054.159249.txt',\n",
       " 'out-3505312677-936-20240404-105019-1712245819.159039.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Raw_Transcriptions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignación de roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tiempo</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Speaker_Asignado_Opt_1</th>\n",
       "      <th>Speaker_Asignado_Opt_2</th>\n",
       "      <th>Speaker_Asignado_Opt_3</th>\n",
       "      <th>Speaker_Asignado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:00:00 - 0:00:03</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Nuestro menú ha cambiado. Escúchalo con atención.</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0:00:07 - 0:00:17</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Para desbloqueo de contraseñas o activación de...</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0:04:23 - 0:05:16</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Buenos días, hola, soy Ana María. ¿Con quién t...</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0:05:18 - 0:05:26</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>¿Me puedes indicar el número de cédula, por fa...</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0:06:05 - 0:06:26</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Muchas gracias por la permanencia. Le indico q...</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0:06:28 - 0:06:33</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Pero, o sea, me acaba de comunicar con nuestro...</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tiempo     Speaker  \\\n",
       "0  0:00:00 - 0:00:03  SPEAKER_00   \n",
       "1  0:00:07 - 0:00:17  SPEAKER_00   \n",
       "2  0:04:23 - 0:05:16  SPEAKER_01   \n",
       "3  0:05:18 - 0:05:26  SPEAKER_01   \n",
       "4  0:06:05 - 0:06:26  SPEAKER_01   \n",
       "5  0:06:28 - 0:06:33  SPEAKER_01   \n",
       "\n",
       "                                               Texto Speaker_Asignado_Opt_1  \\\n",
       "0  Nuestro menú ha cambiado. Escúchalo con atención.                  Liker   \n",
       "1  Para desbloqueo de contraseñas o activación de...                  Liker   \n",
       "2  Buenos días, hola, soy Ana María. ¿Con quién t...                Cliente   \n",
       "3  ¿Me puedes indicar el número de cédula, por fa...                Cliente   \n",
       "4  Muchas gracias por la permanencia. Le indico q...                Cliente   \n",
       "5  Pero, o sea, me acaba de comunicar con nuestro...                Cliente   \n",
       "\n",
       "  Speaker_Asignado_Opt_2 Speaker_Asignado_Opt_3 Speaker_Asignado  \n",
       "0                Cliente                 Empate          Cliente  \n",
       "1                Cliente                 Empate          Cliente  \n",
       "2                  Liker                 Empate            Liker  \n",
       "3                  Liker                 Empate            Liker  \n",
       "4                  Liker                 Empate            Liker  \n",
       "5                  Liker                 Empate            Liker  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Speaker_Asignation('Raw_Transcriptions/force-44441940-972-20240401-112258-1711988578.150759.txt', write_txt = False)[\"Transcripted_Df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del archivo de transcripcion\n",
    "with open(\"Raw_Transcriptions/force-44441940-972-20240401-112258-1711988578.150759.txt\", \"r\", encoding = \"utf-8\") as archivo:\n",
    "    aux_list_df = [] # Lista auxiliar para creacion del df\n",
    "    # Itera sobre cada línea del archivo\n",
    "    for linea in archivo:\n",
    "        # Creacion del dataframe con la transcripcion\n",
    "        transcript = [linea[:17].strip(), linea[19:29].strip(), linea[31:].strip()]\n",
    "        aux_list_df.append(transcript)\n",
    "            \n",
    "    # Creacion del dataframe con la transcripcion\n",
    "    transcript_df = pd.DataFrame(aux_list_df, columns = [\"Tiempo\", \"Speaker\", \"Texto\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

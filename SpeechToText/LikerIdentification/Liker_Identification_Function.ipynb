{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función final para identificación del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacionde requerimientos en caso de ser necesario\n",
    "# pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias necesarias\n",
    "# Importacion de librerias\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Carga del modelo\n",
    "spacy.require_cpu() # Temporal mientras se arregla problema con uso de GPU\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función ya trae por defecto un conjunto de patrones para identificar el Liker pero solo es válido para la campaña de SURA\n",
    "def Speaker_Asignation(file_path, additional_patterns = [], write_txt = True, keep_strategies = True, Word_Count = False, Num_Matches = False, install_requirements = False):\n",
    "    \"\"\"\n",
    "    file_path: path of the transcripted .txt file without the Speaker asignation (i.e each file has either SPEAKER_00 or SPEAKER_01)\n",
    "    write_txt: Specify if you want to create a new .txt file with the asigned roles by the function\n",
    "    additional_patterns: List or dict. Additional patterns to be used in the third strategy (those one not considered or belong to other campaign).\n",
    "    keep_strategies: Include columns of the asigned role in each strategy\n",
    "    Word_Count: Include the number of words spoken by speaker in each line\n",
    "    Num_Matches: Include the number of matches in the considered patterns to search\n",
    "    \"\"\"\n",
    "    # Lectura del archivo de transcripcion\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as archivo:\n",
    "        aux_list_df = [] # Lista auxiliar para creacion del df\n",
    "        # Itera sobre cada línea del archivo\n",
    "        for linea in archivo:\n",
    "            # Creacion del dataframe con la transcripcion\n",
    "            transcript = [linea[:17].strip(), linea[19:29].strip(), linea[31:].strip()]\n",
    "            aux_list_df.append(transcript)\n",
    "            \n",
    "        # Creacion del dataframe con la transcripcion\n",
    "        transcript_df = pd.DataFrame(aux_list_df, columns = [\"Tiempo\", \"Speaker\", \"Texto\"])\n",
    "    \n",
    "    # Solucion 1: Liker = Primer speaker\n",
    "    transcript_df[\"Speaker_Asignado_Opt_1\"] = np.where(transcript_df.Speaker == transcript_df.Speaker[0], \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Solucion 2: Liker =  Persona que mas habla\n",
    "    transcript_df[\"Word_Count\"] = transcript_df.Texto.apply(lambda x: len(x.split())) # Columna auxiliar para contar el numero de palabras en cada fila\n",
    "\n",
    "    # Group by para identificar el Speaker que más habla\n",
    "    words_per_speaker = transcript_df[[\"Speaker\", \"Word_Count\"]].groupby(by = \"Speaker\").sum().reset_index()\n",
    "\n",
    "    # Asignacion del speaker segun que tanto habla\n",
    "    # Lista booleana con el respectivo mapeo\n",
    "    mapping_opt_2 = [words_per_speaker[words_per_speaker.Word_Count == words_per_speaker.Word_Count.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "    transcript_df[\"Speaker_Asignado_Opt_2\"] = np.where(mapping_opt_2, \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Eliminacion de columna auxiliar (Eliminar linea de abajo en caso de querer conservarla)\n",
    "    if not Word_Count:\n",
    "        transcript_df.drop(columns = \"Word_Count\", inplace = True)\n",
    "\n",
    "    # Solucion 3: Conteo del numero de ocurrencias de patrones particulares\n",
    "    # Creacion del matcher para buscar patrones\n",
    "    matcher = Matcher(nlp.vocab) # Matcher\n",
    "    sura_patterns = [[{\"LOWER\": \"sudamericana\"}], [{\"LOWER\": \"de\"}, {\"LOWER\": \"sudamericana\"}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'sura'}}], [{\"LOWER\": \"de\"}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'seguro'}}], [{\"LOWER\": {\"REGEX\": r'seguro'}}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": \"póliza\"}], [{\"LOWER\": \"poliza\"}], [{\"LOWER\": {\"REGEX\": \"cotización\"}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'asegura'}}],\n",
    "                    [{\"LOWER\": \"grabada\"}], [{\"LOWER\": \"monitoreada\"}], [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}],\n",
    "                    [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}, {\"LOWER\": \"y\"}, {\"LOWER\": \"monitoreada\"}],\n",
    "                    [{\"LOWER\": \"validar\"}, {\"LOWER\": \"datos\"}]]\n",
    "    matcher.add(\"sura_patterns\", sura_patterns)\n",
    "    \n",
    "    # Agregacion de patrones adicionales dados por el usuario\n",
    "    if len(additional_patterns) != 0:\n",
    "        additional_patterns_lower = [token.lower() for token in additional_patterns]\n",
    "        patterns = [[{\"LOWER\": token} for token in item.split()] for item in additional_patterns_lower]\n",
    "        matcher.add(\"additional_patterns\", patterns)\n",
    "\n",
    "    # Conteo de cuantos patrones encuentra por speaker\n",
    "    transcript_df[\"Num_Matches\"] = transcript_df.Texto.apply(lambda x: len(matcher(nlp(x))))\n",
    "\n",
    "    # Group by para identificar el Speaker que mas patrones repite\n",
    "    num_matches = transcript_df[[\"Speaker\", \"Num_Matches\"]].groupby(by = \"Speaker\").sum().reset_index().sort_values(\"Num_Matches\", ascending = False)\n",
    "    \n",
    "    # Verificar posible empate\n",
    "    tie = len(num_matches['Num_Matches'].unique()) == 1\n",
    "\n",
    "    if not tie:\n",
    "        # Asignacion del speaker segun numero de matches\n",
    "        # Lista booleana con el respectivo mapeo\n",
    "        mapping_opt_3 = [num_matches[num_matches.Num_Matches == num_matches.Num_Matches.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = np.where(mapping_opt_3, \"Liker\", \"Cliente\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = \"Empate\"\n",
    "\n",
    "    if not Num_Matches:\n",
    "            transcript_df.drop(columns = \"Num_Matches\", inplace = True)\n",
    "    \n",
    "    # SI HAY EMPATE, SE LE DA PRIORIDAD A LA SEGUNDA ESTRATEGGIA (PERSONA QUE MAS HABLA)\n",
    "    if not tie:\n",
    "        # Asignacion final del speaker\n",
    "        bool_df = transcript_df[[\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"]].apply(lambda x: x == \"Liker\")\n",
    "        transcript_df[\"Speaker_Asignado\"] = np.where(np.sum(bool_df, axis = 1).between(2, 3), \"[Liker  ]:\", \"[Cliente]:\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado\"] = transcript_df[\"Speaker_Asignado_Opt_2\"]    \n",
    "    \n",
    "    # Elimnacion de columnas para asignacion final (en caso de requerirse)\n",
    "    if not keep_strategies:\n",
    "        if not tie:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"], inplace = True)\n",
    "        else:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\"], inplace = True)\n",
    "            \n",
    "    # Escribir la transcripción en un archivo txt\n",
    "    if write_txt:\n",
    "        # Lista para   \n",
    "        to_write_list = transcript_df[[\"Tiempo\", \"Speaker_Asignado\", \"Texto\"]].apply(lambda x: \" \".join(x.astype(str)), axis = 1)\n",
    "        # Abrir el archivo en modo de escritura\n",
    "        with open(\"Identified_Speakers\\\\\" + \"Asigned_Speaker_\" + os.path.basename(file_path), 'w', encoding = \"utf-8\") as archivo:\n",
    "            # Iterar sobre la lista y escribir cada texto en una nueva línea\n",
    "            for texto in to_write_list:\n",
    "                archivo.write(texto + '\\n')\n",
    "\n",
    "    return {\"Transcripted_Df\": transcript_df, \"Word_Count\": words_per_speaker, \"Num_Matches\": num_matches}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignación de roles en las transcripciones crudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001764369_1_transcription.txt',\n",
       " '1014249230_3_transcription.txt',\n",
       " '1129574339_6_transcription.txt',\n",
       " '14838701_2_transcription.txt',\n",
       " 'force-44441940-972-20240401-112258-1711988578.150759.txt',\n",
       " 'out-3003958667-994-20240405-163905-1712353145.162469.txt',\n",
       " 'out-3054535186-936-20240401-115437-1711990477.150948.txt',\n",
       " 'out-3103166473-973-20240404-180947-1712272187.160933.txt',\n",
       " 'out-3103465155-956-20240401-132257-1711995777.151309.txt',\n",
       " 'out-3103675012-936-20240404-095452-1712242492.158691.txt',\n",
       " 'out-3103723286-956-20240405-135755-1712343475.161940.txt',\n",
       " 'out-3103814989-913-20240404-161134-1712265094.160513.txt',\n",
       " 'out-3103814989-913-20240405-175919-1712357959.162644.txt',\n",
       " 'out-3103894985-900-20240405-151650-1712348210.162208.txt',\n",
       " 'out-3104294636-980-20240403-162248-1712179368.157746.txt',\n",
       " 'out-3104493260-900-20240402-181030-1712099430.155354.txt',\n",
       " 'out-3104560865-913-20240405-084247-1712324567.161074.txt',\n",
       " 'out-3104875598-900-20240402-141516-1712085316.154263.txt',\n",
       " 'out-3118642729-913-20240405-141059-1712344259.161987.txt',\n",
       " 'out-3125537410-940-20240403-173114-1712183474.158137.txt',\n",
       " 'out-3126588650-966-20240403-175943-1712185183.158207.txt',\n",
       " 'out-3126741945-900-20240404-114213-1712248933.159343.txt',\n",
       " 'out-3145275830-973-20240404-092836-1712240916.158545.txt',\n",
       " 'out-3164213703-913-20240405-104154-1712331714.161339.txt',\n",
       " 'out-3165237464-993-20240405-153645-1712349405.162287.txt',\n",
       " 'out-3167563398-973-20240405-101001-1712329801.161196.txt',\n",
       " 'out-3167682022-993-20240405-114056-1712335256.161634.txt',\n",
       " 'out-3187049147-993-20240401-085542-1711979742.149987.txt',\n",
       " 'out-3193186167-900-20240405-171830-1712355510.162579.txt',\n",
       " 'out-3193186167-900-20240405-172453-1712355893.162589.txt',\n",
       " 'out-3195989894-919-20240401-105207-1711986727.150627.txt',\n",
       " 'out-3202023245-900-20240405-143756-1712345876.162067.txt',\n",
       " 'out-3202776577-966-20240403-081925-1712150365.155641.txt',\n",
       " 'out-3205140598-900-20240405-170331-1712354611.162528.txt',\n",
       " 'out-3205181563-966-20240405-123215-1712338335.161779.txt',\n",
       " 'out-3206151227-940-20240403-153302-1712176382.157436.txt',\n",
       " 'out-3213432785-996-20240401-181641-1712013401.152483.txt',\n",
       " 'out-3215088513-980-20240405-143804-1712345884.162069.txt',\n",
       " 'out-3222529193-998-20240405-142201-1712344921.162016.txt',\n",
       " 'out-3222529193-998-20240405-142814-1712345294.162035.txt',\n",
       " 'out-3225954911-934-20240405-144834-1712346514.162097.txt',\n",
       " 'out-3239315555-956-20240404-112734-1712248054.159249.txt',\n",
       " 'out-3505312677-936-20240404-105019-1712245819.159039.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Raw_Transcriptions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "force-44441940-972-20240401-112258-1711988578.150759.txt\n",
      "out-3104493260-900-20240402-181030-1712099430.155354.txt\n"
     ]
    }
   ],
   "source": [
    "# Archivos con empates en el numero de patrones encontrados\n",
    "for file in os.listdir(\"Raw_Transcriptions/\"):\n",
    "    df = Speaker_Asignation(f\"Raw_Transcriptions/{file}\", write_txt = False)[\"Transcripted_Df\"]\n",
    "    if df.loc[0, \"Speaker_Asignado_Opt_3\"] == \"Empate\":\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tiempo</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Speaker_Asignado_Opt_1</th>\n",
       "      <th>Speaker_Asignado_Opt_2</th>\n",
       "      <th>Speaker_Asignado_Opt_3</th>\n",
       "      <th>Speaker_Asignado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:00:27 - 0:04:36</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Sistema correo de voz Tendrá costo a partir de...</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0:04:45 - 0:05:01</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Para escuchar el mensaje, presiona 1. Para con...</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Liker</td>\n",
       "      <td>Empate</td>\n",
       "      <td>Liker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tiempo     Speaker  \\\n",
       "0  0:00:27 - 0:04:36  SPEAKER_00   \n",
       "1  0:04:45 - 0:05:01  SPEAKER_00   \n",
       "\n",
       "                                               Texto Speaker_Asignado_Opt_1  \\\n",
       "0  Sistema correo de voz Tendrá costo a partir de...                  Liker   \n",
       "1  Para escuchar el mensaje, presiona 1. Para con...                  Liker   \n",
       "\n",
       "  Speaker_Asignado_Opt_2 Speaker_Asignado_Opt_3 Speaker_Asignado  \n",
       "0                  Liker                 Empate            Liker  \n",
       "1                  Liker                 Empate            Liker  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Speaker_Asignation(\"Raw_Transcriptions/out-3104493260-900-20240402-181030-1712099430.155354.txt\", write_txt = False)[\"Transcripted_Df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escritura de archivos con el rol asignado al Speaker (Liker o Cliente)\n",
    "for file in os.listdir(\"Raw_Transcriptions/\"):\n",
    "    Speaker_Asignation(f\"Raw_Transcriptions/{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

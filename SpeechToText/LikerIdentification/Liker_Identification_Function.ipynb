{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función final para identificación del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacionde requerimientos en caso de ser necesario\n",
    "# pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias necesarias\n",
    "# Importacion de librerias\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Carga del modelo\n",
    "spacy.require_cpu() # Temporal mientras se arregla problema con uso de GPU\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función ya trae por defecto un conjunto de patrones para identificar el Liker pero solo es válido para la campaña de SURA\n",
    "def Speaker_Asignation(file_path, additional_patterns = [], write_txt = True, keep_strategies = True, Word_Count = False, Num_Matches = False, install_requirements = False):\n",
    "    \"\"\"\n",
    "    file_path: path of the transcripted .txt file without the Speaker asignation (i.e each file has either SPEAKER_00 or SPEAKER_01)\n",
    "    write_txt: Specify if you want to create a new .txt file with the asigned roles by the function\n",
    "    additional_patterns: List or dict. Additional patterns to be used in the third strategy (those one not considered or belong to other campaign).\n",
    "    keep_strategies: Include columns of the asigned role in each strategy\n",
    "    Word_Count: Include the number of words spoken by speaker in each line\n",
    "    Num_Matches: Include the number of matches in the considered patterns to search\n",
    "    \"\"\"\n",
    "    # Lectura del archivo de transcripcion\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as archivo:\n",
    "        aux_list_df = [] # Lista auxiliar para creacion del df\n",
    "        # Itera sobre cada línea del archivo\n",
    "        for linea in archivo:\n",
    "            # Creacion del dataframe con la transcripcion\n",
    "            transcript = [linea[:17].strip(), linea[19:29].strip(), linea[31:].strip()]\n",
    "            aux_list_df.append(transcript)\n",
    "            \n",
    "        # Creacion del dataframe con la transcripcion\n",
    "        transcript_df = pd.DataFrame(aux_list_df, columns = [\"Tiempo\", \"Speaker\", \"Texto\"])\n",
    "    \n",
    "    # Solucion 1: Liker = Primer speaker\n",
    "    transcript_df[\"Speaker_Asignado_Opt_1\"] = np.where(transcript_df.Speaker == transcript_df.Speaker[0], \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Solucion 2: Liker =  Persona que mas habla\n",
    "    transcript_df[\"Word_Count\"] = transcript_df.Texto.apply(lambda x: len(x.split())) # Columna auxiliar para contar el numero de palabras en cada fila\n",
    "\n",
    "    # Group by para identificar el Speaker que más habla\n",
    "    words_per_speaker = transcript_df[[\"Speaker\", \"Word_Count\"]].groupby(by = \"Speaker\").sum().reset_index()\n",
    "\n",
    "    # Asignacion del speaker segun que tanto habla\n",
    "    # Lista booleana con el respectivo mapeo\n",
    "    mapping_opt_2 = [words_per_speaker[words_per_speaker.Word_Count == words_per_speaker.Word_Count.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "    transcript_df[\"Speaker_Asignado_Opt_2\"] = np.where(mapping_opt_2, \"Liker\", \"Cliente\")\n",
    "\n",
    "    # Eliminacion de columna auxiliar (Eliminar linea de abajo en caso de querer conservarla)\n",
    "    if not Word_Count:\n",
    "        transcript_df.drop(columns = \"Word_Count\", inplace = True)\n",
    "\n",
    "    # Solucion 3: Conteo del numero de ocurrencias de patrones particulares\n",
    "    # Creacion del matcher para buscar patrones\n",
    "    matcher = Matcher(nlp.vocab) # Matcher\n",
    "    sura_patterns = [[{\"LOWER\": \"sudamericana\"}], [{\"LOWER\": \"de\"}, {\"LOWER\": \"sudamericana\"}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'sura'}}], [{\"LOWER\": \"de\"}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'seguro'}}], [{\"LOWER\": {\"REGEX\": r'seguro'}}, {\"LOWER\": {\"REGEX\": r'sura'}}],\n",
    "                    [{\"LOWER\": \"póliza\"}], [{\"LOWER\": \"poliza\"}], [{\"LOWER\": {\"REGEX\": \"cotización\"}}],\n",
    "                    [{\"LOWER\": {\"REGEX\": r'asegura'}}],\n",
    "                    [{\"LOWER\": \"grabada\"}], [{\"LOWER\": \"monitoreada\"}], [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}],\n",
    "                    [{\"LOWER\": \"siendo\"}, {\"LOWER\": \"grabada\"}, {\"LOWER\": \"y\"}, {\"LOWER\": \"monitoreada\"}],\n",
    "                    [{\"LOWER\": \"validar\"}, {\"LOWER\": \"datos\"}]]\n",
    "    matcher.add(\"sura_patterns\", sura_patterns)\n",
    "    \n",
    "    # Agregacion de patrone adicionales dados por el usuario\n",
    "    if len(additional_patterns) != 0:\n",
    "        if isinstance(additional_patterns, list):\n",
    "            additional_patterns_lower = [token.lower() for token in additional_patterns]\n",
    "            patterns = [[{\"LOWER\": token} for token in item.split()] for item in additional_patterns_lower]\n",
    "            matcher.add(\"additional_patterns\", patterns)\n",
    "        elif isinstance(additional_patterns, dict):\n",
    "             matcher.add(additional_patterns)\n",
    "\n",
    "    # Conteo de cuantos patrones encuentra por speaker\n",
    "    transcript_df[\"Num_Matches\"] = transcript_df.Texto.apply(lambda x: len(matcher(nlp(x))))\n",
    "\n",
    "    # Group by para identificar el Speaker que mas patrones repite\n",
    "    num_matches = transcript_df[[\"Speaker\", \"Num_Matches\"]].groupby(by = \"Speaker\").sum().reset_index().sort_values(\"Num_Matches\", ascending = False)\n",
    "    \n",
    "    # Verificar posible empate\n",
    "    tie = len(num_matches['Num_Matches'].unique()) == 1\n",
    "\n",
    "    if not tie:\n",
    "        # Asignacion del speaker segun numero de matches\n",
    "        # Lista booleana con el respectivo mapeo\n",
    "        mapping_opt_3 = [num_matches[num_matches.Num_Matches == num_matches.Num_Matches.max()].Speaker == transcript_df.Speaker[i] for i in range(len(transcript_df.Speaker))]\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = np.where(mapping_opt_3, \"Liker\", \"Cliente\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado_Opt_3\"] = \"Empate\"\n",
    "\n",
    "    if not Num_Matches:\n",
    "            transcript_df.drop(columns = \"Num_Matches\", inplace = True)\n",
    "    \n",
    "    # SI HAY EMPATE, SE LE DA PRIORIDAD A LA SEGUNDA ESTRATEGGIA (PERSONA QUE MAS HABLA)\n",
    "    if not tie:\n",
    "        # Asignacion final del speaker\n",
    "        bool_df = transcript_df[[\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"]].apply(lambda x: x == \"Liker\")\n",
    "        transcript_df[\"Speaker_Asignado\"] = np.where(np.sum(bool_df, axis = 1).between(2, 3), \"[Liker  ]:\", \"[Cliente]:\")\n",
    "    else:\n",
    "        transcript_df[\"Speaker_Asignado\"] = transcript_df[\"Speaker_Asignado_Opt_2\"]    \n",
    "    \n",
    "    # Elimnacion de columnas para asignacion final (en caso de requerirse)\n",
    "    if not keep_strategies:\n",
    "        if not tie:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\", \"Speaker_Asignado_Opt_3\"], inplace = True)\n",
    "        else:\n",
    "            transcript_df.drop(columns = [\"Speaker_Asignado_Opt_1\", \"Speaker_Asignado_Opt_2\"], inplace = True)\n",
    "            \n",
    "    # Escribir la transcripción en un archivo txt\n",
    "    if write_txt:\n",
    "        # Lista para   \n",
    "        to_write_list = transcript_df[[\"Tiempo\", \"Speaker_Asignado\", \"Texto\"]].apply(lambda x: \" \".join(x.astype(str)), axis = 1)\n",
    "        # Abrir el archivo en modo de escritura\n",
    "        with open(\"Identified_Speakers\\\\\" + \"Asigned_Speaker_\" + os.path.basename(file_path), 'w', encoding = \"utf-8\") as archivo:\n",
    "            # Iterar sobre la lista y escribir cada texto en una nueva línea\n",
    "            for texto in to_write_list:\n",
    "                archivo.write(texto + '\\n')\n",
    "\n",
    "    return {\"Transcripted_Df\": transcript_df, \"Word_Count\": words_per_speaker, \"Num_Matches\": num_matches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001764369_1_transcription.txt',\n",
       " '1014249230_3_transcription.txt',\n",
       " '1129574339_6_transcription.txt',\n",
       " '14838701_2_transcription.txt',\n",
       " 'force-44441940-972-20240401-112258-1711988578.150759.txt',\n",
       " 'out-3003958667-994-20240405-163905-1712353145.162469.txt',\n",
       " 'out-3054535186-936-20240401-115437-1711990477.150948.txt',\n",
       " 'out-3103166473-973-20240404-180947-1712272187.160933.txt',\n",
       " 'out-3103465155-956-20240401-132257-1711995777.151309.txt',\n",
       " 'out-3103675012-936-20240404-095452-1712242492.158691.txt',\n",
       " 'out-3103723286-956-20240405-135755-1712343475.161940.txt',\n",
       " 'out-3103814989-913-20240404-161134-1712265094.160513.txt',\n",
       " 'out-3103814989-913-20240405-175919-1712357959.162644.txt',\n",
       " 'out-3103894985-900-20240405-151650-1712348210.162208.txt',\n",
       " 'out-3104294636-980-20240403-162248-1712179368.157746.txt',\n",
       " 'out-3104493260-900-20240402-181030-1712099430.155354.txt',\n",
       " 'out-3104560865-913-20240405-084247-1712324567.161074.txt',\n",
       " 'out-3104875598-900-20240402-141516-1712085316.154263.txt',\n",
       " 'out-3118642729-913-20240405-141059-1712344259.161987.txt',\n",
       " 'out-3125537410-940-20240403-173114-1712183474.158137.txt',\n",
       " 'out-3126588650-966-20240403-175943-1712185183.158207.txt',\n",
       " 'out-3126741945-900-20240404-114213-1712248933.159343.txt',\n",
       " 'out-3145275830-973-20240404-092836-1712240916.158545.txt',\n",
       " 'out-3164213703-913-20240405-104154-1712331714.161339.txt',\n",
       " 'out-3165237464-993-20240405-153645-1712349405.162287.txt',\n",
       " 'out-3167563398-973-20240405-101001-1712329801.161196.txt',\n",
       " 'out-3167682022-993-20240405-114056-1712335256.161634.txt',\n",
       " 'out-3187049147-993-20240401-085542-1711979742.149987.txt',\n",
       " 'out-3193186167-900-20240405-171830-1712355510.162579.txt',\n",
       " 'out-3193186167-900-20240405-172453-1712355893.162589.txt',\n",
       " 'out-3195989894-919-20240401-105207-1711986727.150627.txt',\n",
       " 'out-3202023245-900-20240405-143756-1712345876.162067.txt',\n",
       " 'out-3202776577-966-20240403-081925-1712150365.155641.txt',\n",
       " 'out-3205140598-900-20240405-170331-1712354611.162528.txt',\n",
       " 'out-3205181563-966-20240405-123215-1712338335.161779.txt',\n",
       " 'out-3206151227-940-20240403-153302-1712176382.157436.txt',\n",
       " 'out-3213432785-996-20240401-181641-1712013401.152483.txt',\n",
       " 'out-3215088513-980-20240405-143804-1712345884.162069.txt',\n",
       " 'out-3222529193-998-20240405-142201-1712344921.162016.txt',\n",
       " 'out-3222529193-998-20240405-142814-1712345294.162035.txt',\n",
       " 'out-3225954911-934-20240405-144834-1712346514.162097.txt',\n",
       " 'out-3239315555-956-20240404-112734-1712248054.159249.txt',\n",
       " 'out-3505312677-936-20240404-105019-1712245819.159039.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Raw_Transcriptions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asignación de roles en las transcripciones crudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001764369_1_transcription.txt',\n",
       " '1014249230_3_transcription.txt',\n",
       " '1129574339_6_transcription.txt',\n",
       " '14838701_2_transcription.txt',\n",
       " 'force-44441940-972-20240401-112258-1711988578.150759.txt',\n",
       " 'out-3003958667-994-20240405-163905-1712353145.162469.txt',\n",
       " 'out-3054535186-936-20240401-115437-1711990477.150948.txt',\n",
       " 'out-3103166473-973-20240404-180947-1712272187.160933.txt',\n",
       " 'out-3103465155-956-20240401-132257-1711995777.151309.txt',\n",
       " 'out-3103675012-936-20240404-095452-1712242492.158691.txt',\n",
       " 'out-3103723286-956-20240405-135755-1712343475.161940.txt',\n",
       " 'out-3103814989-913-20240404-161134-1712265094.160513.txt',\n",
       " 'out-3103814989-913-20240405-175919-1712357959.162644.txt',\n",
       " 'out-3103894985-900-20240405-151650-1712348210.162208.txt',\n",
       " 'out-3104294636-980-20240403-162248-1712179368.157746.txt',\n",
       " 'out-3104493260-900-20240402-181030-1712099430.155354.txt',\n",
       " 'out-3104560865-913-20240405-084247-1712324567.161074.txt',\n",
       " 'out-3104875598-900-20240402-141516-1712085316.154263.txt',\n",
       " 'out-3118642729-913-20240405-141059-1712344259.161987.txt',\n",
       " 'out-3125537410-940-20240403-173114-1712183474.158137.txt',\n",
       " 'out-3126588650-966-20240403-175943-1712185183.158207.txt',\n",
       " 'out-3126741945-900-20240404-114213-1712248933.159343.txt',\n",
       " 'out-3145275830-973-20240404-092836-1712240916.158545.txt',\n",
       " 'out-3164213703-913-20240405-104154-1712331714.161339.txt',\n",
       " 'out-3165237464-993-20240405-153645-1712349405.162287.txt',\n",
       " 'out-3167563398-973-20240405-101001-1712329801.161196.txt',\n",
       " 'out-3167682022-993-20240405-114056-1712335256.161634.txt',\n",
       " 'out-3187049147-993-20240401-085542-1711979742.149987.txt',\n",
       " 'out-3193186167-900-20240405-171830-1712355510.162579.txt',\n",
       " 'out-3193186167-900-20240405-172453-1712355893.162589.txt',\n",
       " 'out-3195989894-919-20240401-105207-1711986727.150627.txt',\n",
       " 'out-3202023245-900-20240405-143756-1712345876.162067.txt',\n",
       " 'out-3202776577-966-20240403-081925-1712150365.155641.txt',\n",
       " 'out-3205140598-900-20240405-170331-1712354611.162528.txt',\n",
       " 'out-3205181563-966-20240405-123215-1712338335.161779.txt',\n",
       " 'out-3206151227-940-20240403-153302-1712176382.157436.txt',\n",
       " 'out-3213432785-996-20240401-181641-1712013401.152483.txt',\n",
       " 'out-3215088513-980-20240405-143804-1712345884.162069.txt',\n",
       " 'out-3222529193-998-20240405-142201-1712344921.162016.txt',\n",
       " 'out-3222529193-998-20240405-142814-1712345294.162035.txt',\n",
       " 'out-3225954911-934-20240405-144834-1712346514.162097.txt',\n",
       " 'out-3239315555-956-20240404-112734-1712248054.159249.txt',\n",
       " 'out-3505312677-936-20240404-105019-1712245819.159039.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Raw_Transcriptions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Transcripted_Df':                Tiempo     Speaker  \\\n",
       " 0   0:00:12 - 0:00:12  SPEAKER_01   \n",
       " 1   0:00:12 - 0:00:16  SPEAKER_00   \n",
       " 2   0:00:16 - 0:00:17  SPEAKER_01   \n",
       " 3   0:00:17 - 0:00:20  SPEAKER_00   \n",
       " 4   0:00:21 - 0:00:22  SPEAKER_01   \n",
       " 5   0:00:22 - 0:00:33  SPEAKER_00   \n",
       " 6   0:00:33 - 0:00:34  SPEAKER_01   \n",
       " 7   0:00:34 - 0:00:38  SPEAKER_00   \n",
       " 8   0:00:39 - 0:00:50  SPEAKER_01   \n",
       " 9   0:00:50 - 0:00:58  SPEAKER_00   \n",
       " 10  0:00:59 - 0:01:10  SPEAKER_01   \n",
       " 11  0:01:11 - 0:01:25  SPEAKER_01   \n",
       " 12  0:01:25 - 0:01:36  SPEAKER_00   \n",
       " 13  0:01:38 - 0:01:46  SPEAKER_00   \n",
       " 14  0:01:46 - 0:01:47  SPEAKER_01   \n",
       " 15  0:01:49 - 0:01:54  SPEAKER_00   \n",
       " 16  0:01:55 - 0:02:01  SPEAKER_01   \n",
       " 17  0:02:01 - 0:02:11  SPEAKER_00   \n",
       " 18  0:02:11 - 0:02:12  SPEAKER_01   \n",
       " 19  0:02:12 - 0:02:16  SPEAKER_00   \n",
       " 20  0:02:16 - 0:02:17  SPEAKER_01   \n",
       " 21  0:02:18 - 0:02:21  SPEAKER_00   \n",
       " 22  0:02:22 - 0:02:23  SPEAKER_01   \n",
       " 23  0:02:23 - 0:02:25  SPEAKER_00   \n",
       " 24  0:02:33 - 0:02:36  SPEAKER_00   \n",
       " 25  0:02:36 - 0:02:38  SPEAKER_01   \n",
       " 26  0:02:38 - 0:02:46  SPEAKER_00   \n",
       " 27  0:02:48 - 0:02:54  SPEAKER_00   \n",
       " 28  0:02:56 - 0:04:10  SPEAKER_00   \n",
       " 29  0:04:10 - 0:04:11  SPEAKER_01   \n",
       " 30  0:04:13 - 0:04:17  SPEAKER_00   \n",
       " 31  0:04:18 - 0:04:22  SPEAKER_00   \n",
       " 32  0:04:25 - 0:04:29  SPEAKER_00   \n",
       " 33  0:04:29 - 0:04:31  SPEAKER_01   \n",
       " 34  0:04:33 - 0:04:36  SPEAKER_01   \n",
       " 35  0:04:36 - 0:04:42  SPEAKER_00   \n",
       " 36  0:04:42 - 0:04:49  SPEAKER_01   \n",
       " 37  0:04:49 - 0:04:56  SPEAKER_00   \n",
       " 38  0:04:56 - 0:05:17  SPEAKER_01   \n",
       " 39  0:05:17 - 0:05:26  SPEAKER_00   \n",
       " 40  0:05:26 - 0:05:28  SPEAKER_01   \n",
       " \n",
       "                                                 Texto Speaker_Asignado_Opt_1  \\\n",
       " 0                                                 Aló                  Liker   \n",
       " 1    Sí, buenas tardes, hablo con Edgar Camilo Blanco                Cliente   \n",
       " 2                                          Sí, con él                  Liker   \n",
       " 3   Hola, Blasco Juliano Jaramillo de Segurosura, ...                Cliente   \n",
       " 4                                       Bien, gracias                  Liker   \n",
       " 5   Ay, qué bueno, me alegro Es que abrimos en nue...                Cliente   \n",
       " 6                                        Sí, correcto                  Liker   \n",
       " 7   Y estoy curioso, ¿cuándo ingresaste al sistema...                Cliente   \n",
       " 8   Sí, vi los valores y estoy, pues en ese moment...                  Liker   \n",
       " 9   Ajá, bueno, y cuando ingresaste, ¿cuál te llam...                Cliente   \n",
       " 10  Sí, estaba viendo el que viene todo, todo No r...                  Liker   \n",
       " 11  Sí, estoy mirando varias opciones, estoy esper...                  Liker   \n",
       " 12  Claro, si quieres podemos realizar una nueva c...                Cliente   \n",
       " 13  Tenemos pues otros planes Entonces, si quieres...                Cliente   \n",
       " 14                    Sí, sería mi correo electrónico                  Liker   \n",
       " 15  Listo Bueno, yo te voy a confirmar entonces lo...                Cliente   \n",
       " 16  No, aún no ha salido, porque lo compraste la s...                  Liker   \n",
       " 17  Listo, bueno, entonces, ¿va a quedar entonces ...                Cliente   \n",
       " 18                                       Correcto, sí                  Liker   \n",
       " 19  Listo, ¿y el vehículo va a ser de uso personal...                Cliente   \n",
       " 20                                           Personal                  Liker   \n",
       " 21  Listo ¿Y cuál sería la ciudad de mayor circula...                Cliente   \n",
       " 22                                        Bucaramanga                  Liker   \n",
       " 23                        Dame un momento, un momento                Cliente   \n",
       " 24                Tengo que es un modelo 2018 Mazda 2                Cliente   \n",
       " 25                                           Correcto                  Liker   \n",
       " 26  Entonces, mira, seguro sobre asegura tu vehícu...                Cliente   \n",
       " 27  Este plan que te voy a ofrecer se llama plan u...                Cliente   \n",
       " 28  Responsabilidad civil o unos daños a terceros ...                Cliente   \n",
       " 29                                        ¿Cómo dice?                  Liker   \n",
       " 30                          6.022.663 pesos 6.022.663                Cliente   \n",
       " 31             ¿Y ese valor se puede pagar? 3.022.000                Cliente   \n",
       " 32             3.022.000 No, esa cosa es 6, 6.022.000                Cliente   \n",
       " 33                                    ¿6 millones? Sí                  Liker   \n",
       " 34                       Listo, ¿y qué más me decías?                  Liker   \n",
       " 35  Y ese valor se puede pagar pues así de manera ...                Cliente   \n",
       " 36  Eso es sólo asegurado el vehículo, ¿verdad? Só...                  Liker   \n",
       " 37  Pues tiene el vehículo, responsabilidad civil,...                Cliente   \n",
       " 38  Ok, listo Entonces si quieres envíame esa coti...                  Liker   \n",
       " 39  Listo, claro que sí, entonces ya te la envío a...                Cliente   \n",
       " 40                              Listo, muchas gracias                  Liker   \n",
       " \n",
       "    Speaker_Asignado_Opt_2 Speaker_Asignado_Opt_3 Speaker_Asignado  \n",
       " 0                 Cliente                Cliente       [Cliente]:  \n",
       " 1                   Liker                  Liker       [Liker  ]:  \n",
       " 2                 Cliente                Cliente       [Cliente]:  \n",
       " 3                   Liker                  Liker       [Liker  ]:  \n",
       " 4                 Cliente                Cliente       [Cliente]:  \n",
       " 5                   Liker                  Liker       [Liker  ]:  \n",
       " 6                 Cliente                Cliente       [Cliente]:  \n",
       " 7                   Liker                  Liker       [Liker  ]:  \n",
       " 8                 Cliente                Cliente       [Cliente]:  \n",
       " 9                   Liker                  Liker       [Liker  ]:  \n",
       " 10                Cliente                Cliente       [Cliente]:  \n",
       " 11                Cliente                Cliente       [Cliente]:  \n",
       " 12                  Liker                  Liker       [Liker  ]:  \n",
       " 13                  Liker                  Liker       [Liker  ]:  \n",
       " 14                Cliente                Cliente       [Cliente]:  \n",
       " 15                  Liker                  Liker       [Liker  ]:  \n",
       " 16                Cliente                Cliente       [Cliente]:  \n",
       " 17                  Liker                  Liker       [Liker  ]:  \n",
       " 18                Cliente                Cliente       [Cliente]:  \n",
       " 19                  Liker                  Liker       [Liker  ]:  \n",
       " 20                Cliente                Cliente       [Cliente]:  \n",
       " 21                  Liker                  Liker       [Liker  ]:  \n",
       " 22                Cliente                Cliente       [Cliente]:  \n",
       " 23                  Liker                  Liker       [Liker  ]:  \n",
       " 24                  Liker                  Liker       [Liker  ]:  \n",
       " 25                Cliente                Cliente       [Cliente]:  \n",
       " 26                  Liker                  Liker       [Liker  ]:  \n",
       " 27                  Liker                  Liker       [Liker  ]:  \n",
       " 28                  Liker                  Liker       [Liker  ]:  \n",
       " 29                Cliente                Cliente       [Cliente]:  \n",
       " 30                  Liker                  Liker       [Liker  ]:  \n",
       " 31                  Liker                  Liker       [Liker  ]:  \n",
       " 32                  Liker                  Liker       [Liker  ]:  \n",
       " 33                Cliente                Cliente       [Cliente]:  \n",
       " 34                Cliente                Cliente       [Cliente]:  \n",
       " 35                  Liker                  Liker       [Liker  ]:  \n",
       " 36                Cliente                Cliente       [Cliente]:  \n",
       " 37                  Liker                  Liker       [Liker  ]:  \n",
       " 38                Cliente                Cliente       [Cliente]:  \n",
       " 39                  Liker                  Liker       [Liker  ]:  \n",
       " 40                Cliente                Cliente       [Cliente]:  ,\n",
       " 'Word_Count':       Speaker  Word_Count\n",
       " 0  SPEAKER_00         568\n",
       " 1  SPEAKER_01         196,\n",
       " 'Num_Matches':       Speaker  Num_Matches\n",
       " 0  SPEAKER_00           12\n",
       " 1  SPEAKER_01            4}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Speaker_Asignation(\"Raw_Transcriptions/out-3103465155-956-20240401-132257-1711995777.151309.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"Raw_Transcriptions/\"):\n",
    "    Speaker_Asignation(f\"Raw_Transcriptions/{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

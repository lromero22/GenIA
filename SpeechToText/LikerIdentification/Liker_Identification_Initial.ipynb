{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificacion del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.require_cpu()\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar las líneas de la transcripción\n",
    "transcription_dict = {}\n",
    "\n",
    "# Abre el archivo en modo lectura\n",
    "with open(\"PruebaFuncion.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    # Itera sobre cada línea del archivo\n",
    "    for linea in archivo:\n",
    "        # Obtiene los primeros 30 caracteres como clave\n",
    "        clave = linea[:30].strip()\n",
    "        # Agrega la línea al diccionario con los primeros 30 caracteres como clave\n",
    "        transcription_dict[clave] = linea[31:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Serie de pandas con cada linea de la transcripcion\n",
    "transcription_serie = pd.Series(transcription_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_21996\\3857824047.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  line1 = nlp(transcription_serie[2])\n",
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_21996\\3857824047.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  line2 = nlp(transcription_serie[5])\n"
     ]
    }
   ],
   "source": [
    "line1 = nlp(transcription_serie[2])\n",
    "line2 = nlp(transcription_serie[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0:00:21 - 0:00:26 [SPEAKER_00]': 'Hola, buenas tardes, me gusta hablar con el señor Alejandro.',\n",
       " '0:00:27 - 0:00:28 [SPEAKER_01]': '¿Y con él habla?',\n",
       " '0:00:28 - 0:00:30 [SPEAKER_00]': 'Con Natalia Montoya de Sudamericana, ¿cómo has estado?',\n",
       " '0:00:31 - 0:00:32 [SPEAKER_01]': '¿De dónde, perdón?',\n",
       " '0:00:33 - 0:00:35 [SPEAKER_00]': 'Natalia Montoya de Sudamericana.',\n",
       " '0:00:35 - 0:00:37 [SPEAKER_01]': 'Hola Natalia, ¿cómo estás?',\n",
       " '0:00:37 - 0:00:49 [SPEAKER_00]': 'Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.',\n",
       " '0:00:50 - 0:00:53 [SPEAKER_01]': 'La carácter llegó al mismo día que hablábamos.',\n",
       " '0:00:54 - 0:00:55 [SPEAKER_00]': '¿Cómo?',\n",
       " '0:00:55 - 0:00:58 [SPEAKER_01]': 'La carácter llegó al mismo día.',\n",
       " '0:00:58 - 0:01:11 [SPEAKER_00]': 'Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?',\n",
       " '0:01:12 - 0:01:13 [SPEAKER_01]': '¿Visto de una?',\n",
       " '0:01:13 - 0:01:16 [SPEAKER_00]': 'Muchas gracias Alejandro, una excelente tarde.',\n",
       " '0:01:16 - 0:01:17 [SPEAKER_01]': 'Natalia, una vez concluido, gracias.',\n",
       " '0:01:19 - 0:01:20 [SPEAKER_00]': 'Que estés bien, hasta luego.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documento: Objeto de clase doc al cual se le aplican los métodos del modelo nlp\n",
    "* nlp.vocab: Vocabulario del modelo en cuestion (En este caso: es_core_news_sm.)\n",
    "* matcher: objeto para \"matchear\" tokens o lemas en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Con', 8110129090154140942, 'Natalia', 'PROPN') []\n",
      "('Natalia', 414, 'cómo', 'PRON') [Con, Montoya, Sudamericana, ,]\n",
      "('Montoya', 2666271516716718244, 'Natalia', 'PROPN') []\n",
      "('de', 8110129090154140942, 'Sudamericana', 'PROPN') []\n",
      "('Sudamericana', 2666271516716718244, 'Natalia', 'PROPN') [de]\n",
      "(',', 445, 'Natalia', 'PROPN') []\n",
      "('¿', 445, 'cómo', 'PRON') []\n",
      "('cómo', 8206900633647566924, 'cómo', 'PRON') [Natalia, ¿, has, estado, ?]\n",
      "('has', 411, 'cómo', 'PRON') []\n",
      "('estado', 411, 'cómo', 'PRON') []\n",
      "('?', 445, 'cómo', 'PRON') []\n"
     ]
    }
   ],
   "source": [
    "for _ in line1:\n",
    "    print((_.text, _.dep, _.head.text, _.head.pos_), [child for child in _.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con True 19.893991 True\n",
      "Natalia True 20.198109 True\n",
      "Montoya True 20.47704 True\n",
      "de True 19.03265 True\n",
      "Sudamericana True 18.483267 True\n",
      ", True 17.524149 True\n",
      "¿ True 18.555973 True\n",
      "cómo True 18.316883 True\n",
      "has True 18.840048 True\n",
      "estado True 16.902134 True\n",
      "? True 19.281822 True\n"
     ]
    }
   ],
   "source": [
    "for token in line1:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con Natalia Montoya de Sudamericana, ¿cómo has estado? <-> Hola Natalia, ¿cómo estás? 0.7506478739117178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_21996\\461831088.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(line1, \"<->\", line2, line1.similarity(line2))\n"
     ]
    }
   ],
   "source": [
    "print(line1, \"<->\", line2, line1.similarity(line2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# transcription_serie[0] es el texto\n",
    "line1 # Documento\n",
    "matcher = Matcher(nlp.vocab) # Matcher\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

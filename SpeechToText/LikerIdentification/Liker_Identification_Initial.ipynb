{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificacion del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.require_cpu()\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar las líneas de la transcripción\n",
    "transcription_dict = {}\n",
    "\n",
    "# Abre el archivo en modo lectura\n",
    "with open(\"PruebaFuncion.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    # Itera sobre cada línea del archivo\n",
    "    for linea in archivo:\n",
    "        # Obtiene los primeros 30 caracteres como clave\n",
    "        clave = linea[:30].strip()\n",
    "        # Agrega la línea al diccionario con los primeros 30 caracteres como clave\n",
    "        transcription_dict[clave] = linea[31:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Serie de pandas con cada linea de la transcripcion\n",
    "transcription_serie = pd.Series(transcription_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hola, buenas tardes, me gusta hablar con el señor Alejandro.,\n",
       " ¿Y con él habla?,\n",
       " Con Natalia Montoya de Sudamericana, ¿cómo has estado?,\n",
       " ¿De dónde, perdón?,\n",
       " Natalia Montoya de Sudamericana.,\n",
       " Hola Natalia, ¿cómo estás?,\n",
       " Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.,\n",
       " La carácter llegó al mismo día que hablábamos.,\n",
       " ¿Cómo?,\n",
       " La carácter llegó al mismo día.,\n",
       " Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?,\n",
       " ¿Visto de una?,\n",
       " Muchas gracias Alejandro, una excelente tarde.,\n",
       " Natalia, una vez concluido, gracias.,\n",
       " Que estés bien, hasta luego.]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hola, buenas tardes, me gusta hablar con el señor Alejandro.,\n",
       " ¿Y con él habla?,\n",
       " Con Natalia Montoya de Sudamericana, ¿cómo has estado?,\n",
       " ¿De dónde, perdón?,\n",
       " Natalia Montoya de Sudamericana.,\n",
       " Hola Natalia, ¿cómo estás?,\n",
       " Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.,\n",
       " La carácter llegó al mismo día que hablábamos.,\n",
       " ¿Cómo?,\n",
       " La carácter llegó al mismo día.,\n",
       " Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?,\n",
       " ¿Visto de una?,\n",
       " Muchas gracias Alejandro, una excelente tarde.,\n",
       " Natalia, una vez concluido, gracias.,\n",
       " Que estés bien, hasta luego.]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_nlp = [nlp(transcription_serie.iloc[i]) for i in range(len(transcription_dict))]\n",
    "lines_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0:00:21 - 0:00:26 [SPEAKER_00]': 'Hola, buenas tardes, me gusta hablar con el señor Alejandro.', '0:00:27 - 0:00:28 [SPEAKER_01]': '¿Y con él habla?', '0:00:28 - 0:00:30 [SPEAKER_00]': 'Con Natalia Montoya de Sudamericana, ¿cómo has estado?', '0:00:31 - 0:00:32 [SPEAKER_01]': '¿De dónde, perdón?', '0:00:33 - 0:00:35 [SPEAKER_00]': 'Natalia Montoya de Sudamericana.', '0:00:35 - 0:00:37 [SPEAKER_01]': 'Hola Natalia, ¿cómo estás?', '0:00:37 - 0:00:49 [SPEAKER_00]': 'Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.', '0:00:50 - 0:00:53 [SPEAKER_01]': 'La carácter llegó al mismo día que hablábamos.', '0:00:54 - 0:00:55 [SPEAKER_00]': '¿Cómo?', '0:00:55 - 0:00:58 [SPEAKER_01]': 'La carácter llegó al mismo día.', '0:00:58 - 0:01:11 [SPEAKER_00]': 'Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?', '0:01:12 - 0:01:13 [SPEAKER_01]': '¿Visto de una?', '0:01:13 - 0:01:16 [SPEAKER_00]': 'Muchas gracias Alejandro, una excelente tarde.', '0:01:16 - 0:01:17 [SPEAKER_01]': 'Natalia, una vez concluido, gracias.', '0:01:19 - 0:01:20 [SPEAKER_00]': 'Que estés bien, hasta luego.'}\n",
      "['0:00:21 - 0:00:26 [SPEAKER_00]', '0:00:27 - 0:00:28 [SPEAKER_01]', '0:00:28 - 0:00:30 [SPEAKER_00]', '0:00:31 - 0:00:32 [SPEAKER_01]', '0:00:33 - 0:00:35 [SPEAKER_00]', '0:00:35 - 0:00:37 [SPEAKER_01]', '0:00:37 - 0:00:49 [SPEAKER_00]', '0:00:50 - 0:00:53 [SPEAKER_01]', '0:00:54 - 0:00:55 [SPEAKER_00]', '0:00:55 - 0:00:58 [SPEAKER_01]', '0:00:58 - 0:01:11 [SPEAKER_00]', '0:01:12 - 0:01:13 [SPEAKER_01]', '0:01:13 - 0:01:16 [SPEAKER_00]', '0:01:16 - 0:01:17 [SPEAKER_01]', '0:01:19 - 0:01:20 [SPEAKER_00]']\n"
     ]
    }
   ],
   "source": [
    "print(transcription_dict)\n",
    "transcription_dict_keys = [key for key in transcription_dict]\n",
    "print(transcription_dict_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documento: Objeto de clase doc al cual se le aplican los métodos del modelo nlp\n",
    "* nlp.vocab: Vocabulario del modelo en cuestion (En este caso: es_core_news_sm.)\n",
    "* matcher: objeto para \"matchear\" tokens o lemas en el documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Y con él habla? <-> Con Natalia Montoya de Sudamericana, ¿cómo has estado? 0.6317010697458268\n"
     ]
    }
   ],
   "source": [
    "print(lines_nlp[1], \"<->\", lines_nlp[2], lines_nlp[1].similarity(lines_nlp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEAKER_00] <-> [SPEAKER_01] 0.44632267227081834\n",
      "[SPEAKER_01] <-> [SPEAKER_00] 0.6317010697458268\n",
      "[SPEAKER_00] <-> [SPEAKER_01] 0.7087297937234474\n",
      "[SPEAKER_01] <-> [SPEAKER_00] -0.002456506653392736\n",
      "[SPEAKER_00] <-> [SPEAKER_01] -0.09376746096712618\n",
      "[SPEAKER_01] <-> [SPEAKER_00] 0.3610768864698873\n",
      "[SPEAKER_00] <-> [SPEAKER_01] 0.4075759790502675\n",
      "[SPEAKER_01] <-> [SPEAKER_00] -0.06827931741614186\n",
      "[SPEAKER_00] <-> [SPEAKER_01] -0.10861288437789038\n",
      "[SPEAKER_01] <-> [SPEAKER_00] 0.4383715484271254\n",
      "[SPEAKER_00] <-> [SPEAKER_01] 0.6244443239524881\n",
      "[SPEAKER_01] <-> [SPEAKER_00] 0.3307808339753566\n",
      "[SPEAKER_00] <-> [SPEAKER_01] 0.8709402134537724\n",
      "[SPEAKER_01] <-> [SPEAKER_00] 0.5951982799615461\n",
      "No more iterable\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.3185616250075307\n",
      "[SPEAKER_01] <-> [SPEAKER_01] 0.753502332996219\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.31907464508295497\n",
      "[SPEAKER_01] <-> [SPEAKER_01] 0.7869896337640725\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.06041286003478208\n",
      "[SPEAKER_01] <-> [SPEAKER_01] -0.04665052350524641\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.17764051883093698\n",
      "[SPEAKER_01] <-> [SPEAKER_01] 0.944547439938329\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.3852019228063191\n",
      "[SPEAKER_01] <-> [SPEAKER_01] 0.20730341724195347\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.5341018358275836\n",
      "[SPEAKER_01] <-> [SPEAKER_01] 0.28843768449836965\n",
      "[SPEAKER_00] <-> [SPEAKER_00] 0.5182222867077729\n",
      "No more iterable\n",
      "No more iterable\n",
      "0.3672875308297132\n",
      "0.403641975325506\n"
     ]
    }
   ],
   "source": [
    "# Similarity among lines\n",
    "sim_inter = []\n",
    "sim_intra = []\n",
    "# Diferent speaker\n",
    "for i in range(len(transcription_dict)):\n",
    "    try:\n",
    "        curr_line = nlp(transcription_serie.iloc[i])\n",
    "        next_line = nlp(transcription_serie.iloc[i + 1])\n",
    "        print(f\"{transcription_dict_keys[i][18:31]} <-> {transcription_dict_keys[i+1][18:31]} {curr_line.similarity(next_line)}\")\n",
    "        sim_inter.append(curr_line.similarity(next_line))\n",
    "    except IndexError:\n",
    "        print(\"No more iterable\")\n",
    "\n",
    "# Same speaker\n",
    "for i in range(len(transcription_dict)):\n",
    "    try:\n",
    "        curr_line = nlp(transcription_serie.iloc[i])\n",
    "        next_line = nlp(transcription_serie.iloc[i + 2])\n",
    "        print(f\"{transcription_dict_keys[i][18:31]} <-> {transcription_dict_keys[i+2][18:31]} {curr_line.similarity(next_line)}\")\n",
    "        sim_intra.append(curr_line.similarity(next_line))\n",
    "    except IndexError:\n",
    "        print(\"No more iterable\")\n",
    "\n",
    "print(np.array(sim_inter).mean())\n",
    "print(np.array(sim_intra).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "# Creacion del dataframe para modelacion\n",
    "num_df = pd.DataFrame([nlp(transcription_serie.iloc[i]).vector for i in range(len(transcription_dict))],\n",
    "                       columns = [f\"C{i}\" for i in range(1, 301)])\n",
    "\n",
    "# Estandarizacion del conjunto de datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "std_df = pd.DataFrame(std_scaler.fit_transform(num_df), columns = num_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 3)\n",
    "array_output = kmeans.fit(std_df)\n",
    "kmeans.predict(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SPEAKER_00', 'SPEAKER_01', 'SPEAKER_00', 'SPEAKER_01',\n",
       "       'SPEAKER_00', 'SPEAKER_01', 'SPEAKER_00', 'SPEAKER_01',\n",
       "       'SPEAKER_00', 'SPEAKER_01', 'SPEAKER_00', 'SPEAKER_01',\n",
       "       'SPEAKER_00', 'SPEAKER_01', 'SPEAKER_00'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Trabajo adicional: anadir las etiquetas del speaker al df preprocesado\n",
    "label = pd.Series([transcription_dict_keys[i][19:29] for i in range(len(transcription_dict_keys))], name = \"label\")\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(std_df, label)\n",
    "rfc.predict(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de trnascripciones adicionales para tener más datos de modelacion\n",
    "new_transcriptions = [\"PruebaFuncion.txt\", \"1001764369_1_transcription.txt\", \"1014249230_3_transcription.txt\"]\n",
    "for file in new_transcriptions:\n",
    "    curr_transcription_dict = {}\n",
    "\n",
    "    # Abre el archivo en modo lectura\n",
    "    with open(\"PruebaFuncion.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "        # Itera sobre cada línea del archivo\n",
    "        for linea in archivo:\n",
    "            # Obtiene los primeros 30 caracteres como clave\n",
    "            clave = linea[:30].strip()\n",
    "            # Agrega la línea al diccionario con los primeros 30 caracteres como clave\n",
    "            curr_transcription_dict[clave] = linea[31:].strip()\n",
    "    \n",
    "    curr_transcription_serie = pd.Series(curr_transcription_dict)\n",
    "    # Dataframe con todas los mapeos vectoriales de las transcripciones\n",
    "    try:\n",
    "        curr_df = pd.DataFrame([nlp(curr_transcription_serie.iloc[i]).vector for i in range(len(curr_transcription_dict))],\n",
    "                        columns = [f\"C{i}\" for i in range(1, 301)])\n",
    "        full_df = pd.concat([full_df, aux_df], axis = 0)\n",
    "    except:\n",
    "        full_df = pd.DataFrame([nlp(curr_transcription_serie.iloc[i]).vector for i in range(len(curr_transcription_dict))],\n",
    "                        columns = [f\"C{i}\" for i in range(1, 301)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>C291</th>\n",
       "      <th>C292</th>\n",
       "      <th>C293</th>\n",
       "      <th>C294</th>\n",
       "      <th>C295</th>\n",
       "      <th>C296</th>\n",
       "      <th>C297</th>\n",
       "      <th>C298</th>\n",
       "      <th>C299</th>\n",
       "      <th>C300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328283</td>\n",
       "      <td>1.090309</td>\n",
       "      <td>-1.220418</td>\n",
       "      <td>0.962584</td>\n",
       "      <td>-0.930668</td>\n",
       "      <td>-0.592875</td>\n",
       "      <td>-0.076361</td>\n",
       "      <td>1.149444</td>\n",
       "      <td>0.530069</td>\n",
       "      <td>1.248128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.593561</td>\n",
       "      <td>0.834209</td>\n",
       "      <td>-0.700328</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>-0.497485</td>\n",
       "      <td>0.829342</td>\n",
       "      <td>-0.354436</td>\n",
       "      <td>-1.236176</td>\n",
       "      <td>0.204135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.863921</td>\n",
       "      <td>-2.883483</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>-0.137663</td>\n",
       "      <td>-1.567217</td>\n",
       "      <td>-0.696238</td>\n",
       "      <td>2.936158</td>\n",
       "      <td>-0.511078</td>\n",
       "      <td>-1.738775</td>\n",
       "      <td>...</td>\n",
       "      <td>2.850612</td>\n",
       "      <td>0.823790</td>\n",
       "      <td>-0.515750</td>\n",
       "      <td>-0.624516</td>\n",
       "      <td>-0.289630</td>\n",
       "      <td>-1.333705</td>\n",
       "      <td>-2.316395</td>\n",
       "      <td>-0.161667</td>\n",
       "      <td>0.421498</td>\n",
       "      <td>-3.635435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057989</td>\n",
       "      <td>-0.472658</td>\n",
       "      <td>0.844627</td>\n",
       "      <td>-0.066852</td>\n",
       "      <td>0.228114</td>\n",
       "      <td>-0.620995</td>\n",
       "      <td>0.501056</td>\n",
       "      <td>1.329964</td>\n",
       "      <td>-1.185049</td>\n",
       "      <td>-0.785865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075079</td>\n",
       "      <td>0.853001</td>\n",
       "      <td>-1.687008</td>\n",
       "      <td>-0.797436</td>\n",
       "      <td>0.085937</td>\n",
       "      <td>-0.923636</td>\n",
       "      <td>-3.098727</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>-0.503525</td>\n",
       "      <td>-2.508836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198363</td>\n",
       "      <td>0.779017</td>\n",
       "      <td>0.470010</td>\n",
       "      <td>-1.071750</td>\n",
       "      <td>-2.227845</td>\n",
       "      <td>-0.744143</td>\n",
       "      <td>0.719777</td>\n",
       "      <td>2.671380</td>\n",
       "      <td>-0.218778</td>\n",
       "      <td>-1.919000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547950</td>\n",
       "      <td>1.272577</td>\n",
       "      <td>-0.202263</td>\n",
       "      <td>-1.092417</td>\n",
       "      <td>0.547860</td>\n",
       "      <td>-0.388016</td>\n",
       "      <td>-3.280637</td>\n",
       "      <td>1.054856</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>-3.086503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.308516</td>\n",
       "      <td>-0.310811</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>-0.173558</td>\n",
       "      <td>-0.822890</td>\n",
       "      <td>-0.600572</td>\n",
       "      <td>2.146100</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>1.397562</td>\n",
       "      <td>-2.160164</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.328730</td>\n",
       "      <td>-0.392764</td>\n",
       "      <td>0.448207</td>\n",
       "      <td>-0.750166</td>\n",
       "      <td>1.077416</td>\n",
       "      <td>-0.487230</td>\n",
       "      <td>-0.662598</td>\n",
       "      <td>0.625854</td>\n",
       "      <td>-0.623123</td>\n",
       "      <td>-0.329356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.506127</td>\n",
       "      <td>-0.941736</td>\n",
       "      <td>0.066129</td>\n",
       "      <td>-0.669249</td>\n",
       "      <td>-0.813354</td>\n",
       "      <td>-1.644579</td>\n",
       "      <td>-0.675354</td>\n",
       "      <td>3.101543</td>\n",
       "      <td>-1.289271</td>\n",
       "      <td>-1.280070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790020</td>\n",
       "      <td>0.906233</td>\n",
       "      <td>-1.388271</td>\n",
       "      <td>-0.222479</td>\n",
       "      <td>-0.313640</td>\n",
       "      <td>-0.625910</td>\n",
       "      <td>-4.002300</td>\n",
       "      <td>0.793751</td>\n",
       "      <td>-1.401782</td>\n",
       "      <td>-2.896692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.391805</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>-0.186529</td>\n",
       "      <td>-1.500271</td>\n",
       "      <td>0.209987</td>\n",
       "      <td>-2.588806</td>\n",
       "      <td>-0.771039</td>\n",
       "      <td>1.078378</td>\n",
       "      <td>-0.620437</td>\n",
       "      <td>2.743180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024039</td>\n",
       "      <td>1.643382</td>\n",
       "      <td>-0.783249</td>\n",
       "      <td>-0.220886</td>\n",
       "      <td>-1.061793</td>\n",
       "      <td>-0.262549</td>\n",
       "      <td>-1.002735</td>\n",
       "      <td>0.344641</td>\n",
       "      <td>-0.759934</td>\n",
       "      <td>-0.486681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.492466</td>\n",
       "      <td>1.455245</td>\n",
       "      <td>-1.103410</td>\n",
       "      <td>-0.855522</td>\n",
       "      <td>1.378740</td>\n",
       "      <td>-1.585476</td>\n",
       "      <td>-1.319941</td>\n",
       "      <td>-0.558779</td>\n",
       "      <td>0.601531</td>\n",
       "      <td>-0.431722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628149</td>\n",
       "      <td>-0.364249</td>\n",
       "      <td>-0.219511</td>\n",
       "      <td>-0.019719</td>\n",
       "      <td>0.782373</td>\n",
       "      <td>-1.436222</td>\n",
       "      <td>-0.483689</td>\n",
       "      <td>-0.233292</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.624390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.480747</td>\n",
       "      <td>-2.846670</td>\n",
       "      <td>1.734420</td>\n",
       "      <td>-0.738433</td>\n",
       "      <td>-2.285967</td>\n",
       "      <td>-3.169933</td>\n",
       "      <td>0.274073</td>\n",
       "      <td>3.210133</td>\n",
       "      <td>-1.636726</td>\n",
       "      <td>-6.487457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801213</td>\n",
       "      <td>1.973967</td>\n",
       "      <td>-2.334467</td>\n",
       "      <td>-0.622243</td>\n",
       "      <td>-1.687870</td>\n",
       "      <td>-1.007800</td>\n",
       "      <td>-8.121266</td>\n",
       "      <td>0.775930</td>\n",
       "      <td>-1.597467</td>\n",
       "      <td>-7.716934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.405186</td>\n",
       "      <td>0.868700</td>\n",
       "      <td>-0.350779</td>\n",
       "      <td>-1.123716</td>\n",
       "      <td>1.390714</td>\n",
       "      <td>-1.579269</td>\n",
       "      <td>-0.770353</td>\n",
       "      <td>-0.684014</td>\n",
       "      <td>1.285716</td>\n",
       "      <td>-2.075643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451834</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.669014</td>\n",
       "      <td>-0.101329</td>\n",
       "      <td>1.599643</td>\n",
       "      <td>-0.893300</td>\n",
       "      <td>-1.003529</td>\n",
       "      <td>-0.416017</td>\n",
       "      <td>0.670570</td>\n",
       "      <td>0.530870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.035762</td>\n",
       "      <td>1.093894</td>\n",
       "      <td>-0.428077</td>\n",
       "      <td>-0.444135</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>-1.772890</td>\n",
       "      <td>-0.241739</td>\n",
       "      <td>1.087073</td>\n",
       "      <td>-0.250562</td>\n",
       "      <td>-0.157748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044982</td>\n",
       "      <td>0.568891</td>\n",
       "      <td>-0.168401</td>\n",
       "      <td>-0.993838</td>\n",
       "      <td>0.076436</td>\n",
       "      <td>-0.993251</td>\n",
       "      <td>-1.341758</td>\n",
       "      <td>0.622145</td>\n",
       "      <td>-0.336782</td>\n",
       "      <td>-0.488118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.434098</td>\n",
       "      <td>-1.783311</td>\n",
       "      <td>2.382620</td>\n",
       "      <td>-1.235284</td>\n",
       "      <td>0.582702</td>\n",
       "      <td>-2.547120</td>\n",
       "      <td>0.082076</td>\n",
       "      <td>0.553282</td>\n",
       "      <td>0.800258</td>\n",
       "      <td>-4.890086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693600</td>\n",
       "      <td>0.525480</td>\n",
       "      <td>-1.381613</td>\n",
       "      <td>-1.194906</td>\n",
       "      <td>-0.439230</td>\n",
       "      <td>-1.186040</td>\n",
       "      <td>-5.565200</td>\n",
       "      <td>1.098376</td>\n",
       "      <td>-0.191857</td>\n",
       "      <td>-3.394678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.195226</td>\n",
       "      <td>0.519844</td>\n",
       "      <td>0.124838</td>\n",
       "      <td>0.071174</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>-0.982758</td>\n",
       "      <td>-0.780957</td>\n",
       "      <td>0.608304</td>\n",
       "      <td>-0.025976</td>\n",
       "      <td>0.709442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346569</td>\n",
       "      <td>-0.610050</td>\n",
       "      <td>0.302156</td>\n",
       "      <td>-0.027891</td>\n",
       "      <td>1.459166</td>\n",
       "      <td>-0.395510</td>\n",
       "      <td>-0.905473</td>\n",
       "      <td>0.468914</td>\n",
       "      <td>-1.108723</td>\n",
       "      <td>-0.258588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.268068</td>\n",
       "      <td>0.862776</td>\n",
       "      <td>-0.835539</td>\n",
       "      <td>-0.654650</td>\n",
       "      <td>-0.297888</td>\n",
       "      <td>-1.222437</td>\n",
       "      <td>0.152826</td>\n",
       "      <td>0.784301</td>\n",
       "      <td>-0.125451</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971387</td>\n",
       "      <td>-0.070639</td>\n",
       "      <td>-0.331464</td>\n",
       "      <td>0.266371</td>\n",
       "      <td>2.100482</td>\n",
       "      <td>-0.099362</td>\n",
       "      <td>-0.440891</td>\n",
       "      <td>0.084457</td>\n",
       "      <td>-0.359210</td>\n",
       "      <td>-0.405552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.438437</td>\n",
       "      <td>-0.331713</td>\n",
       "      <td>-0.138299</td>\n",
       "      <td>-0.420139</td>\n",
       "      <td>-1.057364</td>\n",
       "      <td>-1.035547</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>1.471400</td>\n",
       "      <td>-0.353276</td>\n",
       "      <td>1.303014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923941</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>0.288207</td>\n",
       "      <td>0.409256</td>\n",
       "      <td>0.288390</td>\n",
       "      <td>-1.320111</td>\n",
       "      <td>-0.690936</td>\n",
       "      <td>-0.742150</td>\n",
       "      <td>-1.069647</td>\n",
       "      <td>-0.611559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C1        C2        C3        C4        C5        C6        C7  \\\n",
       "0   0.328283  1.090309 -1.220418  0.962584 -0.930668 -0.592875 -0.076361   \n",
       "1  -0.241453  0.863921 -2.883483 -0.602433 -0.137663 -1.567217 -0.696238   \n",
       "2   0.057989 -0.472658  0.844627 -0.066852  0.228114 -0.620995  0.501056   \n",
       "3  -1.198363  0.779017  0.470010 -1.071750 -2.227845 -0.744143  0.719777   \n",
       "4   1.308516 -0.310811  0.999562 -0.173558 -0.822890 -0.600572  2.146100   \n",
       "5  -0.506127 -0.941736  0.066129 -0.669249 -0.813354 -1.644579 -0.675354   \n",
       "6   1.391805  0.935658 -0.186529 -1.500271  0.209987 -2.588806 -0.771039   \n",
       "7   1.492466  1.455245 -1.103410 -0.855522  1.378740 -1.585476 -1.319941   \n",
       "8  -1.480747 -2.846670  1.734420 -0.738433 -2.285967 -3.169933  0.274073   \n",
       "9   1.405186  0.868700 -0.350779 -1.123716  1.390714 -1.579269 -0.770353   \n",
       "10 -0.035762  1.093894 -0.428077 -0.444135  0.008768 -1.772890 -0.241739   \n",
       "11  0.434098 -1.783311  2.382620 -1.235284  0.582702 -2.547120  0.082076   \n",
       "12  2.195226  0.519844  0.124838  0.071174  0.569149 -0.982758 -0.780957   \n",
       "13  2.268068  0.862776 -0.835539 -0.654650 -0.297888 -1.222437  0.152826   \n",
       "14  0.438437 -0.331713 -0.138299 -0.420139 -1.057364 -1.035547 -0.459191   \n",
       "\n",
       "          C8        C9       C10  ...      C291      C292      C293      C294  \\\n",
       "0   1.149444  0.530069  1.248128  ...  0.820123  0.593561  0.834209 -0.700328   \n",
       "1   2.936158 -0.511078 -1.738775  ...  2.850612  0.823790 -0.515750 -0.624516   \n",
       "2   1.329964 -1.185049 -0.785865  ...  0.075079  0.853001 -1.687008 -0.797436   \n",
       "3   2.671380 -0.218778 -1.919000  ...  0.547950  1.272577 -0.202263 -1.092417   \n",
       "4   0.155900  1.397562 -2.160164  ... -2.328730 -0.392764  0.448207 -0.750166   \n",
       "5   3.101543 -1.289271 -1.280070  ...  0.790020  0.906233 -1.388271 -0.222479   \n",
       "6   1.078378 -0.620437  2.743180  ...  1.024039  1.643382 -0.783249 -0.220886   \n",
       "7  -0.558779  0.601531 -0.431722  ...  0.628149 -0.364249 -0.219511 -0.019719   \n",
       "8   3.210133 -1.636726 -6.487457  ...  0.801213  1.973967 -2.334467 -0.622243   \n",
       "9  -0.684014  1.285716 -2.075643  ...  0.451834 -0.491091 -0.669014 -0.101329   \n",
       "10  1.087073 -0.250562 -0.157748  ...  0.044982  0.568891 -0.168401 -0.993838   \n",
       "11  0.553282  0.800258 -4.890086  ... -0.693600  0.525480 -1.381613 -1.194906   \n",
       "12  0.608304 -0.025976  0.709442  ...  0.346569 -0.610050  0.302156 -0.027891   \n",
       "13  0.784301 -0.125451  0.866468  ...  0.971387 -0.070639 -0.331464  0.266371   \n",
       "14  1.471400 -0.353276  1.303014  ...  0.923941  0.310150  0.288207  0.409256   \n",
       "\n",
       "        C295      C296      C297      C298      C299      C300  \n",
       "0   0.158556 -0.497485  0.829342 -0.354436 -1.236176  0.204135  \n",
       "1  -0.289630 -1.333705 -2.316395 -0.161667  0.421498 -3.635435  \n",
       "2   0.085937 -0.923636 -3.098727  0.054159 -0.503525 -2.508836  \n",
       "3   0.547860 -0.388016 -3.280637  1.054856  0.150100 -3.086503  \n",
       "4   1.077416 -0.487230 -0.662598  0.625854 -0.623123 -0.329356  \n",
       "5  -0.313640 -0.625910 -4.002300  0.793751 -1.401782 -2.896692  \n",
       "6  -1.061793 -0.262549 -1.002735  0.344641 -0.759934 -0.486681  \n",
       "7   0.782373 -1.436222 -0.483689 -0.233292  0.621519  0.624390  \n",
       "8  -1.687870 -1.007800 -8.121266  0.775930 -1.597467 -7.716934  \n",
       "9   1.599643 -0.893300 -1.003529 -0.416017  0.670570  0.530870  \n",
       "10  0.076436 -0.993251 -1.341758  0.622145 -0.336782 -0.488118  \n",
       "11 -0.439230 -1.186040 -5.565200  1.098376 -0.191857 -3.394678  \n",
       "12  1.459166 -0.395510 -0.905473  0.468914 -1.108723 -0.258588  \n",
       "13  2.100482 -0.099362 -0.440891  0.084457 -0.359210 -0.405552  \n",
       "14  0.288390 -1.320111 -0.690936 -0.742150 -1.069647 -0.611559  \n",
       "\n",
       "[15 rows x 300 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# transcription_serie[0] es el texto\n",
    "lines_nlp[1] # Documento\n",
    "matcher = Matcher(nlp.vocab) # Matcher\n",
    "sura_patterns = [[{\"LOWER\": \"sudamericana\"}], [{\"LOWER\": \"sura\"}]]\n",
    "matcher.add(\"sura_patterns\", sura_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0:00:21 - 0:00:26 [SPEAKER_00]': 'Hola, buenas tardes, me gusta hablar con el señor Alejandro.',\n",
       " '0:00:27 - 0:00:28 [SPEAKER_01]': '¿Y con él habla?',\n",
       " '0:00:28 - 0:00:30 [SPEAKER_00]': 'Con Natalia Montoya de Sudamericana, ¿cómo has estado?',\n",
       " '0:00:31 - 0:00:32 [SPEAKER_01]': '¿De dónde, perdón?',\n",
       " '0:00:33 - 0:00:35 [SPEAKER_00]': 'Natalia Montoya de Sudamericana.',\n",
       " '0:00:35 - 0:00:37 [SPEAKER_01]': 'Hola Natalia, ¿cómo estás?',\n",
       " '0:00:37 - 0:00:49 [SPEAKER_00]': 'Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.',\n",
       " '0:00:50 - 0:00:53 [SPEAKER_01]': 'La carácter llegó al mismo día que hablábamos.',\n",
       " '0:00:54 - 0:00:55 [SPEAKER_00]': '¿Cómo?',\n",
       " '0:00:55 - 0:00:58 [SPEAKER_01]': 'La carácter llegó al mismo día.',\n",
       " '0:00:58 - 0:01:11 [SPEAKER_00]': 'Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?',\n",
       " '0:01:12 - 0:01:13 [SPEAKER_01]': '¿Visto de una?',\n",
       " '0:01:13 - 0:01:16 [SPEAKER_00]': 'Muchas gracias Alejandro, una excelente tarde.',\n",
       " '0:01:16 - 0:01:17 [SPEAKER_01]': 'Natalia, una vez concluido, gracias.',\n",
       " '0:01:19 - 0:01:20 [SPEAKER_00]': 'Que estés bien, hasta luego.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[(15611239717794066353, 4, 5)]\n",
      "[]\n",
      "[(15611239717794066353, 3, 4)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for lines in lines_nlp:\n",
    "    print(matcher(lines))\n",
    "#matcher(lines_nlp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con con\n",
      "Natalia Natalia\n",
      "Montoya Montoya\n",
      "de de\n",
      "Sudamericana Sudamericana\n",
      ", ,\n",
      "¿ ¿\n",
      "cómo cómo\n",
      "has haber\n",
      "estado estar\n",
      "? ?\n"
     ]
    }
   ],
   "source": [
    "for _ in lines_nlp[2]:\n",
    "    print(_.text, _.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificacion del Liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.require_cpu()\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar las líneas de la transcripción\n",
    "transcription_dict = {}\n",
    "\n",
    "# Abre el archivo en modo lectura\n",
    "with open(\"PruebaFuncion.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    # Itera sobre cada línea del archivo\n",
    "    for linea in archivo:\n",
    "        # Obtiene los primeros 30 caracteres como clave\n",
    "        clave = linea[:30].strip()\n",
    "        # Agrega la línea al diccionario con los primeros 30 caracteres como clave\n",
    "        transcription_dict[clave] = linea[31:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Serie de pandas con cada linea de la transcripcion\n",
    "transcription_serie = pd.Series(transcription_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "line0 = nlp(transcription_serie.iloc[0])\n",
    "line1 = nlp(transcription_serie.iloc[1])\n",
    "line2 = nlp(transcription_serie.iloc[2])\n",
    "line3 = nlp(transcription_serie.iloc[3])\n",
    "line4 = nlp(transcription_serie.iloc[4])\n",
    "line5 = nlp(transcription_serie.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0:00:21 - 0:00:26 [SPEAKER_00]': 'Hola, buenas tardes, me gusta hablar con el señor Alejandro.',\n",
       " '0:00:27 - 0:00:28 [SPEAKER_01]': '¿Y con él habla?',\n",
       " '0:00:28 - 0:00:30 [SPEAKER_00]': 'Con Natalia Montoya de Sudamericana, ¿cómo has estado?',\n",
       " '0:00:31 - 0:00:32 [SPEAKER_01]': '¿De dónde, perdón?',\n",
       " '0:00:33 - 0:00:35 [SPEAKER_00]': 'Natalia Montoya de Sudamericana.',\n",
       " '0:00:35 - 0:00:37 [SPEAKER_01]': 'Hola Natalia, ¿cómo estás?',\n",
       " '0:00:37 - 0:00:49 [SPEAKER_00]': 'Muy bien, muchas gracias. Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar, o si aún no te ha llegado para reenviártela.',\n",
       " '0:00:50 - 0:00:53 [SPEAKER_01]': 'La carácter llegó al mismo día que hablábamos.',\n",
       " '0:00:54 - 0:00:55 [SPEAKER_00]': '¿Cómo?',\n",
       " '0:00:55 - 0:00:58 [SPEAKER_01]': 'La carácter llegó al mismo día.',\n",
       " '0:00:58 - 0:01:11 [SPEAKER_00]': 'Ah, bueno, perfecto. Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza, que quedó desde el 23 de marzo del 2024. ¿Para qué le pasó? Que desde ese día está protegida tu mundo, ¿visto?',\n",
       " '0:01:12 - 0:01:13 [SPEAKER_01]': '¿Visto de una?',\n",
       " '0:01:13 - 0:01:16 [SPEAKER_00]': 'Muchas gracias Alejandro, una excelente tarde.',\n",
       " '0:01:16 - 0:01:17 [SPEAKER_01]': 'Natalia, una vez concluido, gracias.',\n",
       " '0:01:19 - 0:01:20 [SPEAKER_00]': 'Que estés bien, hasta luego.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documento: Objeto de clase doc al cual se le aplican los métodos del modelo nlp\n",
    "* nlp.vocab: Vocabulario del modelo en cuestion (En este caso: es_core_news_sm.)\n",
    "* matcher: objeto para \"matchear\" tokens o lemas en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Con', 8110129090154140942, 'Natalia', 'PROPN') []\n",
      "('Natalia', 8206900633647566924, 'Natalia', 'PROPN') [Con, Montoya, Sudamericana, estado]\n",
      "('Montoya', 2666271516716718244, 'Natalia', 'PROPN') []\n",
      "('de', 8110129090154140942, 'Sudamericana', 'PROPN') []\n",
      "('Sudamericana', 2666271516716718244, 'Natalia', 'PROPN') [de]\n",
      "(',', 445, 'estado', 'VERB') []\n",
      "('¿', 445, 'estado', 'VERB') []\n",
      "('cómo', 435, 'estado', 'VERB') []\n",
      "('has', 405, 'estado', 'VERB') []\n",
      "('estado', 414, 'Natalia', 'PROPN') [,, ¿, cómo, has, ?]\n",
      "('?', 445, 'estado', 'VERB') []\n"
     ]
    }
   ],
   "source": [
    "for _ in line1:\n",
    "    print((_.text, _.dep, _.head.text, _.head.pos_), [child for child in _.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con True 50.8328 False\n",
      "Natalia True 22.096422 False\n",
      "Montoya True 18.616274 False\n",
      "de True 60.041386 False\n",
      "Sudamericana True 18.090414 False\n",
      ", True 33.25681 False\n",
      "¿ True 72.05523 False\n",
      "cómo True 47.562153 False\n",
      "has True 70.721375 False\n",
      "estado True 38.38651 False\n",
      "? True 58.019497 False\n"
     ]
    }
   ],
   "source": [
    "for token in line1:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con Natalia Montoya de Sudamericana, ¿cómo has estado? <-> Hola Natalia, ¿cómo estás? 0.7757885336824693\n"
     ]
    }
   ],
   "source": [
    "print(line1, \"<->\", line2, line1.similarity(line2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line1.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alejandro PER\n"
     ]
    }
   ],
   "source": [
    "for ent in line0.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# transcription_serie[0] es el texto\n",
    "line1 # Documento\n",
    "matcher = Matcher(nlp.vocab) # Matcher\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.863921</td>\n",
       "      <td>-2.883483</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>-0.137663</td>\n",
       "      <td>-1.567217</td>\n",
       "      <td>-0.696238</td>\n",
       "      <td>2.936158</td>\n",
       "      <td>-0.511078</td>\n",
       "      <td>-1.738775</td>\n",
       "      <td>...</td>\n",
       "      <td>2.850612</td>\n",
       "      <td>0.823790</td>\n",
       "      <td>-0.515750</td>\n",
       "      <td>-0.624516</td>\n",
       "      <td>-0.289630</td>\n",
       "      <td>-1.333705</td>\n",
       "      <td>-2.316395</td>\n",
       "      <td>-0.161667</td>\n",
       "      <td>0.421498</td>\n",
       "      <td>-3.635435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328283</td>\n",
       "      <td>1.090309</td>\n",
       "      <td>-1.220418</td>\n",
       "      <td>0.962584</td>\n",
       "      <td>-0.930668</td>\n",
       "      <td>-0.592875</td>\n",
       "      <td>-0.076361</td>\n",
       "      <td>1.149444</td>\n",
       "      <td>0.530069</td>\n",
       "      <td>1.248128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.593561</td>\n",
       "      <td>0.834209</td>\n",
       "      <td>-0.700328</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>-0.497485</td>\n",
       "      <td>0.829342</td>\n",
       "      <td>-0.354436</td>\n",
       "      <td>-1.236176</td>\n",
       "      <td>0.204135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.241453  0.863921 -2.883483 -0.602433 -0.137663 -1.567217 -0.696238   \n",
       "1  0.328283  1.090309 -1.220418  0.962584 -0.930668 -0.592875 -0.076361   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  2.936158 -0.511078 -1.738775  ...  2.850612  0.823790 -0.515750 -0.624516   \n",
       "1  1.149444  0.530069  1.248128  ...  0.820123  0.593561  0.834209 -0.700328   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.289630 -1.333705 -2.316395 -0.161667  0.421498 -3.635435  \n",
       "1  0.158556 -0.497485  0.829342 -0.354436 -1.236176  0.204135  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([line1.vector, line0.vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.39562"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linalg.norm(line1.vector - line4.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LikerIdentification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

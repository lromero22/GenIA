{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Keyword find"
      ],
      "metadata": {
        "id": "VzSyjSst2veH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preproceso para unir, todos los textos de un speaker"
      ],
      "metadata": {
        "id": "ZAT2QXrT22M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OS BASED PATH\n",
        "# base = Path(__file__).resolve().parent\n",
        "# Notebook Path\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# All files and directories ending with .txt and that don't begin with a dot:\n",
        "base = os.path.abspath('')\n",
        "file_paths = glob(f\"{base}/*.txt\")\n",
        "input_files = [os.path.basename(file_path) for file_path in file_paths]\n",
        "print(input_files)\n",
        "\n",
        "nombre_salida = \"transcribe\""
      ],
      "metadata": {
        "id": "M6pIkrqlM0we",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15150121-4e2c-4d0c-dbbb-6a10de541bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['transcribe_4339_6.txt', 'transcribe_8701_2.txt', 'transcribe_9230_3.txt', 'transcribe_4369_1.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "speakers1_times = {}\n",
        "speakers2_times = {}\n",
        "speakers1_dict = {}\n",
        "speakers2_dict = {}\n",
        "for numero_diar, input_file in enumerate(input_files):\n",
        "  with open(input_file, \"r\", encoding=\"UTF-8\") as f:\n",
        "      transcribe = f.readlines()\n",
        "\n",
        "  # Extract the last 6 digits from the file name\n",
        "  if len(input_file.split('.')) > 2:\n",
        "    id_file = input_file.split('.')[1]\n",
        "  else:\n",
        "    id_file = input_file.split('.')[-2][-6:]\n",
        "\n",
        "  # Keyword preprocessing\n",
        "  speaker1 = [line for line in transcribe if \"SPEAKER_00\" in line]\n",
        "  speaker2 = [line for line in transcribe if \"SPEAKER_01\" in line]\n",
        "\n",
        "  # Join the lines of each speaker\n",
        "  speaker1 = \" \".join(speaker1)\n",
        "  speaker2 = \" \".join(speaker2)\n",
        "\n",
        "  # Save the timestamps of talking of each speaker\n",
        "  pattern = r\"\\d{1,2}:\\d{2}:\\d{2} - \\d{1,2}:\\d{2}:\\d{2} \\[SPEAKER_00]:\"\n",
        "  speaker1_tmp = re.findall(pattern, speaker1)\n",
        "  speaker1_tmp = [timestamp.replace(\" [SPEAKER_00]:\", \"\") for timestamp in speaker1_timestamps]\n",
        "  speakers1_times[id_file] = speaker1_tmp\n",
        "\n",
        "  pattern = r\"\\d{1,2}:\\d{2}:\\d{2} - \\d{1,2}:\\d{2}:\\d{2} \\[SPEAKER_01]:\"\n",
        "  speaker2_tmp = re.findall(pattern, speaker2)\n",
        "  speaker2_tmp = [timestamp.replace(\" [SPEAKER_01]:\", \"\") for timestamp in speaker2_timestamps]\n",
        "  speakers2_times[id_file] = speaker2_tmp\n",
        "\n",
        "  # Remove the strings that match the pattern 00:00:00 - 0:00:26 [SPEAKER_00]:\n",
        "  pattern = r\"\\d{1,2}:\\d{2}:\\d{2} - \\d{1,2}:\\d{2}:\\d{2} \\[SPEAKER_\\d{2}\\]:\"\n",
        "  # Save the lines without timestamp\n",
        "  speaker1 = re.sub(pattern, \"\", speaker1)\n",
        "  speaker2 = re.sub(pattern, \"\", speaker2)\n",
        "\n",
        "  speaker1 = speaker1.split(\"\\n\")\n",
        "  speaker2 = speaker2.split(\"\\n\")\n",
        "  speakers1_dict[id_file] = speaker1\n",
        "  speakers2_dict[id_file] = speaker2\n"
      ],
      "metadata": {
        "id": "MiJA7aAQ21eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(speakers1_dict)\n",
        "print(speakers2_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_BGYpa6X_lo",
        "outputId": "f4df15b5-56ae-4b2a-a5ee-4cf2e3d4055a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4339_6': [' Bien, gracias a Dios. Qué bueno. Muy bien, muchas gracias. Me alegro que estés muy bien.', '  En fin, ¿qué es la reducción? Probar el cliente que, por ejemplo, yo golpeé el carro, no tengo protección.', '  Yo recorro en un carro, no que se robe, sino que un día se va a caer por ahí y eso no vale.', '  A mí me divertí.', '  Pues en ese caso tendrías cobertura en daños a terceros.', '  No, por eso te escribí. No, yo te he enviado la cotización. Tú la tienes en el WhatsApp.', '  ¿Tienes alguna cosa con ustedes? Ninguna.', '  Eso es teórico. Porque ahora mismo, ahora mismo, yo estoy con el mío. Si me meto en una peyota, se va a decir 500, 500, 500 pesos. Seguro que me llevo a hacer el tránsito y acaso me doleré por la barra. Es verdad, esto es un accidente de tránsito.', '  Y en Colombia, ni en Bogotá, ni en Río de la Mar, el árbitro.', '  Sí, tienes razón, tienes razón, ese valor, sí, a veces es muy alto.', '  Sí, sinceramente.', '  Perfectamente, te entiendo perfectamente.', '  Sí, entonces entiendo todo eso, pero no es lo mismo que en el otro.', '  Sí, te entiendo, te entiendo perfectamente. Y si tú no quieres responder, pierdo. Sí, te comprendo perfectamente.', '  En el carro anterior, que me había asesinado con mi mujer, si no me he robado...', '  Porque para subir el seguro con los clientes...', '  Sí, señor.', '  A tu favor, yo no voy a salir en toda la tarde. Ya en la cinco yo te defino enseguida si tú vas a hacer la cuota por los tres minutos.', '  Así que me llamas, pero te llamaba.', ''], '8701_2': [' Aló Aló, buenas tardes, me vuelvo a hablar con el señor Alejandro', '  Con Natalia Montoya de Suramericana, ¿cómo has estado?', '  Natalia Montoya de Suramericana', '  Muy bien, muchas gracias Bueno, te estoy contactando para validar contigo si ya te llegó toda la documentación, la carácter de la póliza, si ya la pudiste validar o si aún no te ha llegado para reenviártela', '  ¿Cómo?', '  Ah, bueno, perfecto Entonces, pues la idea es que era confirmar el registro de evidencia de tu póliza Quedó desde el 23 de marzo del 2024 ¿Para qué le pasó? Que desde ese día está protegida tu módulo visto Visto de una Muchas gracias Alejandro, un excelente trabajo', ''], '9230_3': [' Hola, buenas tardes, Laura.', '  Hola, Laura, nuevamente con Helen de Sura. ¿Cómo vas?', '  Ah, bueno, no, que te quería preguntar, cuéntame si hiciste la inspección de la moto.', '  Ah, sí, señora, sí, aquí sí revisa. Lo que pasa es que estaba colocándome la placa, discúlpame. Por eso te llamaba, porque yo no me ofrecía ningún resultado. Bueno, sí, te fue muy bien. El vehículo es asegurable por $6,900,000 y $250,000 en accesorios que corresponden a una parrilla por $130,000 y barras protectoras por $120,000. Ok. Listo, entonces, ¿te parece bien si en ese momento procedemos a pedirle a la póliza ya para finalizar el proceso?', '  Listo, te recuerdo, pues, que por seguridad, la llamada está siendo grabada y monitoreada. Voy a validar nuevamente los datos para ver. Voy a verificar que todo es que viene en la póliza. Tu cédula es de ciudadanía, número 1014-249. ¿Me confirma los últimos tres dígitos? Los tres. Correcto. Te confirmo tu nombre, Laura Paola Roja Rincón. Fecha de nacimiento, 15 de mayo de 1992.', '  Espérame.', '  ¿93? Ajá. ¿93?', '  ¿Noviembre? 18.', '  Eso es en noviembre de 93. Espérame, entonces.', '  Listo. Celular que te estoy llamando. Se los confirmo. 313-683-4840. Y correo, laura2017rojas.com.', '  Listo.', '  Dirección tengo, calle 68, número 119-82 en negativa. Sí. ¿Tienes teléfono fijo?', '  Listo.', '  Entonces, según el resultado de inspección, la moto carácter circular como se indica, por $6,900,000 y $250,000 en accesorios. La placa APP es A, A, P, papá, P, papá, 60, gato.', '  Listo.', '  TBS, APAC, RTR, 206, CONED, modelo 2022. Circula principalmente en Bogotá. Y el uso que le hace es particular personal, ¿cierto? Sí. Entonces, va a quedar asegurada por $7,150,000, pues, incluyendo los accesorios. Te confirmo, entonces, vas a tomar la póliza para pago mensual diferido o de contado.', '  Mensual quedan las cuotas en $64,276.', '  Listo. Te confirmo las coberturas. Entonces, responsabilidad civil con un límite de $840,000,000 de pesos por evento. Pérdida total por daño y por hurto, cobertura del 80% en cada caso. Casos de transporte, $15,000,000 diarios. En caso de pérdida total de la moto, esa por 30 días. Renta diaria por hospitalización de $20,000,000, que te cubre a ti como asegurada. A partir de estar hospitalizada, esa por 30 días. Cobertura llamada accidentes al conductor por $50,000,000 de pesos. Y asistencia para motos. Listo. Te pregunto, Laura, ¿cómo desea realizar el pago de las cuotas mensuales? Puede ser por debilidad.', '  ¿Cómo, perdón?', '  Sí, claro. Por PSD de la página de Seguro Sura.', '  Listo. Espérame, entonces.', '  Indícame, por favor, Laura, la fecha de expedición de tu cédula.', '  ¿2011? Ajá. Eso sí estaba bien. ¿Naciste en Colombia? Sí.', '  ¿La moto tiene prenda con alguna entidad financiera o está libre? Está libre.', '  De acuerdo. ¿Sacar como tomadora, asegurada y beneficiaria de la póliza?', '  Ajá. Te pregunto, ¿eres considerada políticamente expuesta?', '  ¿Tienes relación con una persona considerada políticamente expuesta?', '  Listo. Te recuerdo que puedes realizar el pago de las cuotas mensuales ingresando a la página www.seguro.com.', '  También puedes pagar en corresponsales bancarios como Éxitos Últimas, entre otros. Con la carácter de tu póliza y el condicionado, queremos llegar al detalle de los medios de pago disponibles. Recuerda que se asuma a la vez de cancelar dentro de los siguientes cinco días hábiles para evitar el olvido de pago y que hagan riesgo de cancelación. La opción de pago fraccionada sería 12 meses, cuotas de $676. Recuerda que la póliza tiene renovación automática. Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. Para conocer este proceso, también puedes revisarlo en nuestra página web, www.segurosura.com. Nos autoriza a ser contactada por Suramericana S.A. filiales y subsidiarias para el ofrecimiento de productos y servicios y las demás finalidades contenidas en su política de privacidad, que puedes consultar en www.segurosura.com. Nos autoriza.', '  Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. Para que el vehículo continúe protegido, si desea revocar unilateralmente el contrato de seguro, lo puedes hacer a través de un listo escrito en suramericana. el 75% del valor comercial. Vas a contar con gastos de transporte de 15,000 pesos diarios en caso de pérdida de su autos de la moto por 30 días, renta diaria por hospitalización de 20,000 pesos que te cubre a ti como asegurada a partir del tercer día de estar hospitalizada de esa por 30 días, cobertura llamada accidentes a conductor por 50 millones de pesos y asistencia para motos. Adicionalmente, quiero aclararte que con esta grabación no es necesaria la firma de ninguna documentación. Para no perder sus coberturas, te recomendamos realizar el pago correspondiente en la fecha establecida. Una vez su póliza sea aprobada, será enviada a su nuevo respaldo y condiciones generales al correo electrónico laura2017rojas.com.', '  Te damos entonces la bienvenida a nuestra compañía y te felicitamos por la decisión que acabas de tomar. La póliza está en proceso de validación. Inmediatamente se despide. Te vas a estar llegando tu correo para que revises por favor que esté bien toda la información. Tanto el vehículo como tu información personal. Si es que de pronto hay algo que da modificar, nos cuentas para proceder a realizar la respectiva corrección de acuerdo.', '  Bueno, puedes seguirte en vídeo si quieres por WhatsApp. Ah, bueno, yo te voy a escribir enseguida y tú me respondes porfa para poderte adjuntar en escribirte el INDEPagos. A ti te va a llegar el INDEPagos. A ti inmensamente va a llegar el INDEPagos. A ti inmensamente te va a llegar a tu correo el recibo de pago. Entonces tú ingresas a la página www.segurosura.com.co, vas a Pago Express, ahí digitas tu cédula y ya te aparece el cupón de pago generado. Inmensamente lo puedes pagar de esa manera.', '  Listo. Para reportar cualquier evento, solicitar asistencia, puedes comunicarte el número al triple 8, opción 1. La línea funciona 24-7 y es gratuita desde tu celular. Dependiendo del evento, se te envía la asistencia que corresponda. ¿Listo?', '  Y te pregunto, de pronto se la va a contar a mi hermano que yo le envié la cotización para ver qué tal le pareció.', '  Sí, le envié dos, le envié dos porque la vez que se subió un poco. Un poquito, pues, a diferencia de la tuya, le valía, el plan fue como 2 millones 100 algo y cuotas de 160, por lo que es una moto de alto cilindraje, un valor, pues, superior y si le queda un poquito más alto. Entonces, le coticé otra alternativa, única con mente con pérdidas totales y parciales, que le quedaba como un millón algo. Entonces, me dijo que iba a revisar cuál de las dos le parecía mejor, que me lo contaba por WhatsApp. Ah, ok.', '  Sí, es piloto. Ah, entonces sí, ya tiene plata. Esperemos que se decida por la más completa, entonces.', '  Sí, no, yo quedo súper pendiente, Laura. Bueno, y cualquier cosa que necesites, me cuentas. Te agradezco, pues, mucho por tu tiempo y tu atención y te deseo una feliz Semana Santa. Feliz Semana Santa.', ''], '4369_1': [' Sí, buenas tardes ¿Con Juan Cartagena?', '  Hola, hola ¿Cómo estás?', '  Ay, qué bueno, mi amor Juan, vimos en nuestro sistema tu interés por asegurar tu moto con la póliza a todo riesgo Con placas RKQ33F, ¿es correcto?', '  Listo, Juan, y cuando ingresaste al sistema, ¿pudiste ver los valores?', '  Hola, ¿cuándo ingresaste al sistema, pudiste ver los valores?', '  Listo, Juan, ¿y alguno que te llamara la atención?', '  Sí, claro que sí Te pregunto, Juan, ¿tú eres el que aparece en la tarjeta de propiedad?', '  Listo, en un momento, para que podamos revisar la cotización Te voy entonces a confirmar tu fecha de nacimiento Tengo que es 28 de 9 del 2000, ¿está bien?', '  Te pregunto, ¿la moto es de uso personal o trabajo?', '  ¿Y cuál sería la ciudad de mayor circulación de la moto?', '  Listo, tengo que hacer una modelo 2021 Suzuki TR150, ¿está bien?', '  Entonces, mira, asegura y sobresegura tu moto en un valor de 7.200.000 ¿Qué te va a pedir la póliza con nosotros? ¿Una responsabilidad civil? O unos daños a terceros por un valor de 840 millones de pesos para cada evento Esta cobertura es la más importante porque una persona hasta podría perder su patrimonio Si, digamos, con su vehículo llega a causar daño a otra persona Un vehículo, un Audi o un Mercedes tiene como responder En cambio, con una póliza como esta, le entregarías esa responsabilidad a la aseguradora Y no tendrías que pagar ningún deducible Si en alguno de estos casos requieres o solicitas de un abogado Sura tiene su propio bufete de abogados que te acompañaría en cada caso Y tampoco tendrías que pagar ningún deducible Bueno, bueno, bueno, bueno, bueno, bueno, bueno, bueno, bueno, bueno, bueno Ay, Leonardo Ven', '  Ok Si tu moto llega a tener algún choque y pierde más del 75 Esto quiere decir una pérdida total Seguro Sura te lo cubre al 80% del valor comercial de tu moto Si Frente al hurto Si te lo llegan a adoptar, sea que por un hurto simple o un hurto agravado El hurto simple es que la hagas ahora a tu casa y te la robaron Y el hurto agravado es que te la lleguen a robar con algún arma Sura cubre los dos tipos de hurto Y también al 80% del valor comercial de tu moto', '  En cualquiera de estos dos casos, que sea una pérdida total Y sea por daños o por hurto Como sabemos que en el momento no vas a contar con tu moto Te damos de transporte de 15 mil pesos diarios máximo hasta 30 días ¿Hasta ahí, Buen, esta cara la información?', '  Ahora te voy a contar las coberturas frente al conductor Si llegaras a tener un accidente en la moto y te llegan a hospitalizar Después del tercer día de hospitalización Vas a recibir una renta diaria de 20 mil pesos Máximo hasta 30 días Y si a raíz de ese accidente perdieras más del 50% de tu capacidad laboral O sea una invalidez Recibirías 50 millones de pesos de libre destinación Y si llegaras a fallecer Estos 50 millones de pesos se entregarían a tus beneficiarios de ley Y adicional tenemos unas asistencias Las asistencias de nosotros son a nivel nacional Entonces si te llegas a varar, a pinchar, a quedar sin gasolina Te comunicas con nosotros La línea es 24-7 Indicas lo que te está pasando Y dependiendo del daño tendrían un carretallero de servicio de cruz Ah ok ¿Tienes alguna duda de la póliza?', '  Así la póliza con todas las coberturas tiene un valor anual de 1 millón 49 mil 140 pesos Este valor se puede pagar así de manera anual O también lo podemos fraccionar De manera mensual, trimestral, semestral ¿Cómo te quedaría más fácil?', '  Mensual, entonces sería 12 cotas fijas de 97 mil 6 pesos', '  97 mil', '  6 pesos', '  ¿Ves que cómo vas a valorar tu presupuesto?', '  Digamos hasta que yo te deí es con todas las coberturas Digamos que yo te deí es con todas las coberturas Digamos hasta que yo te deí es con todas las coberturas Digamos ahí ¿Cuáles son las coberturas de las que te mencioné que para ti no sean tan importantes?', '  Listo, sí, es verdad. Es mejor pues uno tener las coberturas completas porque si no no se necesita, ¿cierto?', '  Entonces, si así tendrías pues que todas las coberturas, eso sería pues como tal el valor mensual.', '  97 mil.', '  Sí, señor.', '  Pues la vigencia de la póliza es un año.', '  Por 12 meses, sí. O si quieres te lo cotizo de otra manera, también tenemos trimestral, semestral.', '  Pues las pólizas tienen renovación automática, ¿cierto? Entonces al otro año se renueva demasiado. De alguna manera, si es importante que sepa que es mejor obviamente no tenerla mucho asegurada porque pasará, ¿cierto? Entonces es mejor no tener el seguro.', '  No, esos valores sí los pueden subir según el IPC, pues, en el país.', '  Listo, miren, nosotros debemos de realizarle una inspección. La inspección es completamente gratuita y es virtual, donde debes estar con la moto, la moto debe estar limpia, en un lugar iluminado, yo te enviaría un link, ingresas a ese link, tomas las fotos como te piden, pues, ahí en ese link, tienes que tener a la mano la tarjeta de propiedad y también te comunicas con un técnico por videollamada que te va a hacer otras recomendaciones, como prender la moto, prender las luces. Después de que realices esa inspección, el resultado sale a las 2 horas. Yo ya me comuniqué. Digo, para darte el resultado, si sale asegurable, en la llamada realizaríamos la expedición de tu póliza y cuando terminemos se llega tanto a tu WhatsApp y a tu correo electrónico.', '  Cualquier, o sea, nosotros tenemos la inspección, pues, sí, de lunes a domingos cualquier día.', '  Claro, pues, quizás te quedaría fácil realizarla el día de mañana.', '  O nosotros tenemos, eh...', '  Listo, pero debemos de dejar que día la vas a realizar, eh, porque, pues, para que el técnico se pueda comunicar contigo.', '  ¿Y vas en la moto?', '  Ay, es muy importante que te vayas al viaje con, con la moto asegurada, porque mira que nuestras puerturas son a nivel nacional.', '  Entonces, a veces llegas a varar, a pinchar cualquier cosa y que necesites el servicio.', '  Listo, porque nosotros tenemos el horario de, de lunes a sábado de seis y media a cinco y media para realizar la inspección. Y del domingo de nueve a cinco de la tarde.', '  Eh, pues, yo te enviaría, digamos, esta cotización que acabamos de realizar, yo te la envío hoy a tu WhatsApp. Y cuando tienes alguna, alguna pregunta, me la puedes escribir por ahí, por donde yo envíe la, la cotización.', '  Entonces, ¿te agenda la inspección para qué?', '  O hagamos una cosa. Yo te, eh, te voy a mandar esa cotización. Vamos a realizar a tu WhatsApp. Y yo te envío el link para mañana. Para mañana ese link te, te serviría entre cinco y, entre nueve y cinco de la tarde. O sea, si sea para ingresarlo, puedes, puedes hacerlo el día de mañana. Pero es muy importante. Si, si, si sea para ingresarlo, al momento que lo abras, termine la inspección. Porque no se puede, digamos, abrir y, ah, vuelvo otra vez en, en un momentico. No, no se puede desde iniciar y terminar por completo la inspección.', '  Listo. Y dime, yo ya me comunicaría entonces contigo el lunes para que podamos reajistar. Pero igual te la damos en la inspección para mañana.', '  Bueno, Juan. Ustedes recuerden que hablaste con Juliana Jaramillo de Segurosura.', '']}\n",
            "{'4339_6': [' Hola, buenas tardes. Señor Álvaro, ¿cómo está? Con Ángela de Seguro Sura, ¿cómo ha estado?', '  Pero solo por hurto. O sea, si quieres revisamos bien la carátula y la carátula yo la tengo abierta. Dice lo siguiente. Dice daños a terceros, listo. Dice daños a terceros límite, 1.040 millones. Dice valor que debes pagar en caso de un evento, cero. Deducible, cero. Valor, 1.040 millones. Exacto. Dice daños del carro, pérdida total, valor que debes pagar en un evento, cero. Valor límite suma de la aseguradora, el valor comercial. Y de bajito dice hurto, pérdida total, lo mismo. Valor que debes asumir en caso de un evento, cero. Valor límite o suma de la aseguradora, valor comercial. Y pérdida parcial. Pero esa pérdida parcial se refiere a hurto. Es decir, si se te hurtan partes del vehículo o si se te roban cualquier parte. Y eso quiere decir que si se te roban partes del vehículo, debes pagar el deducible del 10% a un salario mínimo. Y el valor límite de la suma es el valor del daño.', '  Exactamente. La cobertura de pérdida parcial por daño no la tienes. Solo es de manera total.', '  Claro que sí, sí, en eso tienes razón.', '  Si te protegía los daños parciales. En esa no, ya si lo que la quieres anexar, el valor de la cuota te queda 7.000. La primera sí te quedaría en eso de 200.000. 18.000 y las otras te quedarían en 307.000.', '  Pues ese sería el valor incluyendo las pérdidas parciales. Igual sabes que Suramericana es una de las mejores aseguradoras que hay.', '  En caso de que haya algún accidente que por lo general siempre se ve involucrado un tercero, ese sí estaría cubierto al 100%.', '  Yo siempre le he servido la cotización para que la revisen por si tienen alguna pregunta, alguna duda.', '  Sí, desde el comienzo de la cotización ya te había explicado, pensé que te iba a creer.', '  Esos 1.040 millones son por accidente presentado. Nosotros no te damos, es decir, en muchas aseguradoras te dan 500 millones para pagar indemnizaciones, te dan 100 millones para otra cosa. Con nosotros es de manera global. Eso quiere decir que nunca te vas a quedar sin la cobertura en daños a terceros. Porque por accidente presentado vas a contar con 1.040 millones.', '  Sí, eso es cierto. Esos son accidentes de tránsito. Y sí, a veces, es verdad, a veces estos montos son muy altos. Pero, sin embargo, la aseguradora los coloca. Así para que el cliente no vaya a tener que, en ningún evento, tener que pagar dinero. Es mejor que le sobre dinero de los 1.040 millones.', '  Te entiendo perfectamente. Sin embargo, los montos que se manejan en vehículos sí son esos. En motos sí se manejan menor valor. Pero en autos el menor valor, ah, sí creo que son 1.040.', '  Exacto, sin embargo, siempre se coloca ese valor, pues, para que la persona nunca tenga que pagar dinero en caso de alguna eventualidad. ¿Por qué? Porque a veces son choques íntimos, o a veces hay un muerto, o a veces hay que pagar indemnizaciones.', '  Claro que sí, te comprendo.', '  Sin embargo, pues, los talleres que nosotros tenemos para reparación de los vehículos son talleres propios. Los vehículos se recogen directamente con la grúa, tú no tienes que pagar ningún dinero adicional por grúa.', '  Ya, sin embargo, esto...', '  Sí, tienes que definir medio una vez, porque si no la póliza debe ser cancelada. Y tu vehículo de inmediato quedaría desprotegido.', '  El vehículo está protegido porque si tu vehículo se lo llegan a robar en estos momentos, si llegas a necesitar una grúa, el servicio lo puedes solicitar. Si llegas a tener algún tipo de accidente, la aseguradora te va a brindar la asistencia. Exacto, pero si llegas a tener algún tipo de accidente, la aseguradora te va. Nosotros te prestamos el servicio. Y si es en caso de alguna pérdida parcial por daño, lógicamente la reparación en nuestros talleres te va a salir mucho más económica por ser cliente de Sura. Porque todos los vehículos se ingresan directamente en nuestros talleres para ser reparados. Entonces, no estás desprotegido en estos momentos, la póliza está activa. Exactamente, pero solamente es una cobertura por daños. ¿Alguna vez has hecho alguna reclamación por pérdida parcial? ¿Has tenido algún accidente?', '  Sí, yo tenía un accidente. Sí, yo tenía un accidente. Sí, yo tenía un accidente. No entiendo, pero yo te estoy hablando de algún choque. ¿Alguna vez has tenido que hacer alguna reparación? ¿Has tenido que ingresar el vehículo en el taller?', '  Perfecto, entonces ya en ese caso, ¿me cuentas entonces si cancelamos entonces el seguro o lo dejamos entonces como estaba?', '  La póliza, las cuotas se quedan en 307 mil.', '  Y ya te voy a confirmar el valor. Y ya te voy a confirmar el valor exacto del seguro con las pérdidas parciales. Regálame, por favor.', '  La póliza completa te queda en 3.593.103. La primer cuota te queda por el mismo valor que ya se había generado, que serían 216.758. Esa primer cuota te queda exactamente igual porque ya no hay modificación en la primer cuota. Y ya a partir de la segunda... Desde la segunda cuota, desde la segunda hasta la onceava cuota, las cuotas te quedan 306.940.', '  Perfecto, entonces a las cinco te vuelvo a llamar.', ''], '8701_2': [' ¿Y con él habla?', '  ¿De dónde, perdón?', '  Hola Natalia, ¿cómo estás?', '  La carácter llegó el mismo día que hablábamos', '  Llegó el mismo día Sí, llegó el mismo día', '  Natalia, una vez con gusto, gracias', ''], '9230_3': [' Sí, con ella.', '  Hola, Helen. Bien, cuéntame.', '  Sí, sí, sí, creo que ya me llegó el correo, pero no lo he revisado.', '  No, el 10 de mayo de 1993.', '  No.', '  ¿Y mensual cuánto sería?', '  Vale, entonces, no sé.', '  ¿PSD?', '  Ajá.', '  Fecha de expedición del 2011. ¿Cómo, perdón? Primero de diciembre del 2011.', '  Ajá.', '  No.', '  Ok, ¿quiero decir que hay una idea de cómo enviar el pago o acá en la página de cura?', '  Ok, ¿y si tengo algún, digamos, siniestro o algo? Aquí no me lo marco.', '  Ok, listo. Vale, perfecto.', '  Ah, sí, me dijo que tú lo habías llamado y que te dijo que lo llamarás más tarde después de que tú estabas manejando. Ah, ya. ¿Ya le enviaste la cotización?', '  Sí. Ah, ok. Sí, es piloto, entonces tiene plata, te puedo poner.', '  Sí, sí, no, igual yo le dije, lo que vas a decir, es que la talla que me llamó, que estoy, que estaba poniendo algunos platos, un poquito más tranquilo. Ay, no, claro. Es lo que yo estaba escribiendo en estos días.', '  Muy bien. Muy bien.', ''], '4369_1': [' Hola', '  Sí', '  Muy bien', '  Sí', '  ¿Hola?', '  Eh, sí, más o menos', '  Eh, ¿me puedes repetir los valores, por favor?', '  Sí', '  Eh, sí, es uso personal solamente para mí', '  Eh, yo estoy en Río Negro', '  Sí, sí', '  Sí Listo', '  No, no, esto es súper interesante Listo', '  Y mensual, ¿cuánto me tocaría dar cada gota mensual?', '  ¿12 cotas fijas de 90 y qué? 96 mil', '  97 mil', '  97 mil', '  Y no podría caer un poquito Como si pagaran otras cotas en el banco Entonces esto me cae como un poquito para su dico Listo', '  No, todas son importantes porque pues algún robo o que uno se accidenta, ¿sí entiendes? Eso es como lo más importante.', '  Exactamente.', '  ¿Valor mensual de 67 mil pesos?', '  ¿97 mil?', '  ¿Por cuánto?', '  ¿Un año?', '  Bien. ¿Y después del año tiene que seguir pagando?', '  ¿Y cada año se renueva por lo mismo los 97 mil?', '  ¿Y cómo le hace uno para ya colocarlo para ya, cómo te explico, para...? Para asegurarlo. Exactamente.', '  Ah, ok, pero eso lo tienes uno cualquier día que esté ocupado.', '  Ah, eso sí, eso es un domingo que uno no esté ocupado, porque yo en el momento estoy en el trabajo.', '  Eh, mañana, mañana sí, súper ocupado, no sé si me dé porque voy de viaje.', '  Pero, ¿sí me puede, sí me puede mandar el link, porfa, al WhatsApp o a, o al correo?', '  Ah, ya, no sé cómo explicarte, hombre, porque ya esta semana que viene es Semana Santa y no sé si de pronto voy de viaje para el departamento del Chocó.', '  Sí, claro.', '  Sí.', '  Sí, vamos a ver si de pronto mañana, si no me da mañana, ya para el lunes.', '  De nueve a cinco.', '  Y uno puede guardar ese número, ¿cierto?', '  ¿Por el WhatsApp? Sí. Ah, listo, listo, muchas gracias.', '  Chica, es que no sé explicar, no sé cómo explicar, no sé que ella tenga disponible.', '  Listo. Listo.', '  Bueno. Listo. Hágale pues.', '  Listo. Gracias.', '']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword find per item"
      ],
      "metadata": {
        "id": "8AoY2MREAafk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load spanish pipeline"
      ],
      "metadata": {
        "id": "hEV51L56CKUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!python -m spacy download es_core_news_lg\n",
        "# !python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "id": "5AOi4WvTMPZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import spacy\n",
        "\n",
        "def process_speaker_data(speaker_data):\n",
        "    \"\"\"\n",
        "    Process speaker data using spaCy.\n",
        "\n",
        "    Args:\n",
        "    - speaker_data: Dictionary containing the speaker's lines as values.\n",
        "\n",
        "    Returns:\n",
        "    - entities: List of entity labels found in the speaker's lines.\n",
        "    \"\"\"\n",
        "    result_dict = {}\n",
        "\n",
        "    spanish_nlp = spacy.load(\"es_core_news_lg\")\n",
        "    for key, value in speaker_data.items():\n",
        "        lines = [spanish_nlp(line) for line in speaker_data[key]]\n",
        "        result_dict[key] = [ent.label_ for line in lines for ent in line.ents]\n",
        "    # lines = [spanish_nlp(line) for line in speaker_data.values()]\n",
        "    # entities = [ent.label_ for line in lines for ent in line.ents]\n",
        "    return result_dict\n",
        "\n",
        "speaker1_entities = process_speaker_data(speakers1_dict)\n",
        "speaker2_entities = process_speaker_data(speakers2_dict)\n",
        "\n",
        "\n",
        "# spanish_nlp = spacy.load(\"es_core_news_lg\")\n",
        "# nlp = spacy.blank(\"es\", vocab=spanish_nlp.vocab)\n",
        "\n",
        "# #use spacy in each item of the speaker list\n",
        "# # speaker1 = [nlp(line) for line in speaker1]\n",
        "# # speaker2 = [nlp(line) for line in speaker2]\n",
        "# speaker1 = [spanish_nlp(line) for line in speaker1]\n",
        "# speaker2 = [spanish_nlp(line) for line in speaker2]\n",
        "\n",
        "# # Find type of conversation using spacy\n",
        "# # Find the most common entity in the conversation\n",
        "# speaker1_entities = [ent.label_ for line in speaker1 for ent in line.ents]\n",
        "# speaker2_entities = [ent.label_ for line in speaker2 for ent in line.ents]\n",
        "\n",
        "print(speaker1_entities)\n",
        "print(speaker2_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1xBHV_L2z7t",
        "outputId": "3ac78110-c612-4bad-bfab-d95c6be1804e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4339_6': ['MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'LOC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC'], '8701_2': ['PER', 'PER', 'PER', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER'], '9230_3': ['PER', 'LOC', 'MISC', 'PER', 'MISC', 'MISC', 'PER', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'ORG', 'MISC', 'LOC', 'MISC', 'MISC', 'ORG', 'LOC', 'MISC', 'ORG', 'LOC', 'ORG', 'LOC', 'LOC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'PER', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC'], '4369_1': ['PER', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'PER', 'PER', 'LOC', 'PER', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'PER', 'MISC', 'PER', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'PER', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER']}\n",
            "{'4339_6': ['PER', 'PER', 'MISC', 'PER', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC'], '8701_2': ['LOC', 'MISC', 'MISC', 'LOC'], '9230_3': ['LOC', 'MISC', 'MISC', 'ORG', 'MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'ORG', 'PER', 'PER', 'MISC', 'MISC', 'MISC'], '4369_1': ['MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'PER', 'MISC', 'PER', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'LOC', 'LOC', 'MISC', 'MISC']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# displacy.serve(speaker1[5], style=\"ent\")\n",
        "displacy.render(speaker1[5], style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "tu7ebuPmIQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPACY NER Training\n",
        "\n",
        "spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning libraries like Tensor Flow, PyTorch, or MXNet through its machine learning library Thinc."
      ],
      "metadata": {
        "id": "3z8fnK0P7VqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plac"
      ],
      "metadata": {
        "id": "pVWmxlSKEPBC",
        "outputId": "198f724f-b213-444d-de87-877bc4e36cbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plac\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Installing collected packages: plac\n",
            "Successfully installed plac-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "import plac\n",
        "import random\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "b1dEVaxJ7ZpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train set"
      ],
      "metadata": {
        "id": "NA0Q_z6O7si_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entity labels and **definition**\n",
        "\n",
        "* PERSON:      People, including fictional.\n",
        "* NORP:        Nationalities or religious or political groups.\n",
        "* FAC:         Buildings, airports, highways, bridges, etc.\n",
        "* ORG:         Companies, agencies, institutions, etc.\n",
        "* GPE:         Countries, cities, states.\n",
        "* LOC:         Non-GPE locations, mountain ranges, bodies of water.\n",
        "* PRODUCT:     Objects, vehicles, foods, etc. (Not services.)\n",
        "* EVENT:       Named hurricanes, battles, wars, sports events, etc.\n",
        "* WORK_OF_ART: Titles of books, songs, etc.\n",
        "* LAW:         Named documents made into laws.\n",
        "* LANGUAGE:    Any named language.\n",
        "* DATE:        Absolute or relative dates or periods.\n",
        "* TIME:        Times smaller than a day.\n",
        "* PERCENT:     Percentage, including ”%“.\n",
        "* MONEY:       Monetary values, including unit.\n",
        "* QUANTITY:    Measurements, as of weight or distance.\n",
        "* ORDINAL:     “first”, “second”, etc.\n",
        "* CARDINAL:    Numerals that do not fall under another type."
      ],
      "metadata": {
        "id": "8a3h6XRG9o7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexes finding"
      ],
      "metadata": {
        "id": "gqlmeWB4_kwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = 'Exacto, pero si llegas a tener algún tipo de accidente, la aseguradora te va. Nosotros te prestamos el servicio.'\n",
        "substring = 'aseguradora.'\n",
        "type_entity = 'PRODUCT'\n",
        "\n",
        "matches = [(match.start(), match.end()) for match in re.finditer(substring, text)]\n",
        "\n",
        "if matches:\n",
        "    start_index, end_index = matches[0]\n",
        "    print(f\"[({start_index}, {end_index}, '{type_entity}')]\")\n",
        "\n",
        "else:\n",
        "    print(\"Substring not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GawLbE9p8bqm",
        "outputId": "a652ad66-0973-4a50-84dd-a723e89691ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(59, 71, 'PRODUCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMAT\n",
        "# [(Start of the entity to train, End of the entity, Type of entity)]\n",
        "TRAIN_DATA = [\n",
        "    ('Con Natalia Montoya de Sura', {\n",
        "        'entities': [(23, 27, 'ORG')]\n",
        "    }),\n",
        "    ('Con Natalia Montoya de Suramericana', {\n",
        "        'entities': [(23, 35, 'ORG')]\n",
        "    }),\n",
        "    ('Estoy validando contigo si ya te llego la documentación', {\n",
        "    'entities': [(42, 55, 'PRODUCT')]\n",
        "    }),\n",
        "    ('confirmar que la evidencia de tu póliza quedó desde el 23 de marzo del 2024', {\n",
        "        'entities': [(55, 75, 'DATE'), (33, 39, 'PRODUCT')]\n",
        "    }),\n",
        "    ('Sí, claro. Por PSD de la página de Seguro Sura.', {\n",
        "        'entities': [(35, 47, 'PRODUCT')]\n",
        "    }),\n",
        "    ('Exacto, pero si llegas a tener algún tipo de accidente, la aseguradora te va. Nosotros te prestamos el servicio.', {\n",
        "        'entities': [(59, 71, 'PRODUCT')]\n",
        "    }),\n",
        "    # ('confirmar que la evidencia de tu póliza quedó desde el 23 de marzo del 2024', {\n",
        "    #     'entities': [(55, 75, 'DATE'), (33, 39, 'MISC')]\n",
        "    # }),\n",
        "    # ('confirmar que la evidencia de tu póliza quedó desde el 23 de marzo del 2024', {\n",
        "    #     'entities': [(55, 75, 'DATE'), (33, 39, 'MISC')]\n",
        "    # }),\n",
        "]"
      ],
      "metadata": {
        "id": "hC-WrsL_7jB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "variables required for the training model to be processed."
      ],
      "metadata": {
        "id": "wGnA7lY3B4CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OS BASED PATH\n",
        "# base = Path(__file__).resolve().parent\n",
        "# Notebook Path\n",
        "base = os.path.abspath('')\n",
        "\n",
        "output_path = os.path.join(base, \"likers_words\")\n",
        "\n",
        "model = None\n",
        "output_dir=Path(output_path)\n",
        "n_iter=100"
      ],
      "metadata": {
        "id": "3maGYxQYBoJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the model\n",
        "\n",
        "if model is not None:\n",
        "    nlp = spacy.load(model)\n",
        "    print(\"Loaded model '%s'\" % model)\n",
        "else:\n",
        "    nlp = spacy.blank('es')\n",
        "    print(\"Created blank 'es' model\")\n",
        "\n",
        "#set up the pipeline\n",
        "\n",
        "if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe('ner', last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe('ner')"
      ],
      "metadata": {
        "id": "Yop9LIXeBoID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae63f527-9de7-4847-b44e-5ba25ee7be8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created blank 'es' model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " train the recognizer by disabling the unnecessary pipeline except for NER. The nlp_update function can be used to train the recognizer."
      ],
      "metadata": {
        "id": "cs1JwAOmCmFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.training.example import Example\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get('entities'):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "\n",
        "# for batch in spacy.util.minibatch(TRAIN_DATA, size=2):\n",
        "#     for text, annotations in batch:\n",
        "#         # create Example\n",
        "#         doc = nlp.make_doc(text)\n",
        "#         example = Example.from_dict(doc, annotations)\n",
        "#         # Update the model\n",
        "#         nlp.update([example], drop=0.3)\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(n_iter):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        # for text, annotations in tqdm(TRAIN_DATA):\n",
        "\n",
        "        for batch in spacy.util.minibatch(tqdm(TRAIN_DATA), size=2):\n",
        "            for text, annotations in batch:\n",
        "                # create Example\n",
        "                doc = nlp.make_doc(text)\n",
        "                example = Example.from_dict(doc, annotations)\n",
        "                # Update the model\n",
        "                nlp.update([example], drop=0.3)\n",
        "                nlp.update(\n",
        "                  [example],\n",
        "                  drop=0.5,\n",
        "                  sgd=optimizer,\n",
        "                  losses=losses)\n",
        "\n",
        "            # nlp.update(\n",
        "            #     [text],\n",
        "            #     [annotations],\n",
        "            #     drop=0.5,\n",
        "            #     sgd=optimizer,\n",
        "            #     losses=losses)\n",
        "        print(losses)"
      ],
      "metadata": {
        "id": "R_5Rsq0CBoGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test trained model"
      ],
      "metadata": {
        "id": "vqLz3uF9CzbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text, _ in TRAIN_DATA:\n",
        "    doc = nlp(text)\n",
        "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "E2e6MKxeC3DX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605e46f3-a991-4ad6-f8fd-f09cef6e4a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities [('documentación', 'PRODUCT')]\n",
            "Entities [('póliza', 'PRODUCT'), ('23 de marzo del 2024', 'DATE')]\n",
            "Entities [('Suramericana', 'ORG')]\n",
            "Entities [('Seguro Sura.', 'PRODUCT')]\n",
            "Entities []\n",
            "Entities [('Sura', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained model"
      ],
      "metadata": {
        "id": "2Ch598qqDBpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir)"
      ],
      "metadata": {
        "id": "l0SmCcoQDDO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d488998-9ff0-4e58-f038-ad875b01a86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to /content/likers_words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export model folder"
      ],
      "metadata": {
        "id": "FzI93qnMCQ7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/likers_words.zip /content/likers_words"
      ],
      "metadata": {
        "id": "weA-AetUBhnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load trained model"
      ],
      "metadata": {
        "id": "ixZQgamSZY2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import spacy\n",
        "\n",
        "def trained_speaker_data(speaker_data):\n",
        "    \"\"\"\n",
        "    Process speaker data using spaCy.\n",
        "\n",
        "    Args:\n",
        "    - speaker_data: Dictionary containing the speaker's lines as values.\n",
        "\n",
        "    Returns:\n",
        "    - entities: List of entity labels found in the speaker's lines.\n",
        "    \"\"\"\n",
        "    result_dict = {}\n",
        "\n",
        "    print(\"Loading from\", output_dir)\n",
        "    trained_nlp = spacy.load(output_dir)\n",
        "\n",
        "    for key, value in speaker_data.items():\n",
        "        lines = [trained_nlp(line) for line in speaker_data[key]]\n",
        "        result_dict[key] = [ent.label_ for line in lines for ent in line.ents]\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "speaker1_entities = process_speaker_data(speakers1_dict)\n",
        "speaker2_entities = process_speaker_data(speakers2_dict)\n",
        "\n",
        "# speaker1_entities = result_spk1['r']\n",
        "# speaker2_entities = result_spk2['r']\n",
        "\n",
        "print(speaker1_entities)\n",
        "print(speaker2_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDNBU7g3lcCT",
        "outputId": "2ab9eb07-58f8-4b28-b440-0f2c8b59037a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4339_6': ['MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'LOC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC'], '8701_2': ['PER', 'PER', 'PER', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER'], '9230_3': ['PER', 'LOC', 'MISC', 'PER', 'MISC', 'MISC', 'PER', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'ORG', 'MISC', 'LOC', 'MISC', 'MISC', 'ORG', 'LOC', 'MISC', 'ORG', 'LOC', 'ORG', 'LOC', 'LOC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'PER', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC'], '4369_1': ['PER', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'PER', 'PER', 'LOC', 'PER', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'PER', 'MISC', 'PER', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'PER', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'PER']}\n",
            "{'4339_6': ['PER', 'PER', 'MISC', 'PER', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'MISC', 'MISC', 'ORG', 'MISC', 'PER', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC'], '8701_2': ['LOC', 'MISC', 'MISC', 'LOC'], '9230_3': ['LOC', 'MISC', 'MISC', 'ORG', 'MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'MISC', 'MISC', 'ORG', 'PER', 'PER', 'MISC', 'MISC', 'MISC'], '4369_1': ['MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'LOC', 'MISC', 'PER', 'MISC', 'PER', 'LOC', 'MISC', 'MISC', 'PER', 'MISC', 'LOC', 'MISC', 'MISC', 'LOC', 'LOC', 'MISC', 'MISC']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing trained model"
      ],
      "metadata": {
        "id": "XJQaSWXJC5nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(trained_nlp(speakers1_dict[0][0]), style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "XEM66Ugto22w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Loading from\", output_dir)\n",
        "# trained_nlp = spacy.load(output_dir)\n",
        "\n",
        "def count_entity_labels(speakers_dict, model_output_dir, speaker):\n",
        "    # Load the trained NLP model\n",
        "    print(\"Loading from\", model_output_dir)\n",
        "    trained_nlp = spacy.load(model_output_dir)\n",
        "\n",
        "    # Initialize a dictionary to store the counts for each speaker\n",
        "    speaker_entity_counts = {}\n",
        "\n",
        "    # Iterate over each speaker's lines\n",
        "    for key, lines in speakers_dict.items():\n",
        "        # Initialize a dictionary to store the counts of entity labels for this speaker\n",
        "        entity_counts = {}\n",
        "\n",
        "        # Iterate over each line for the current speaker\n",
        "        for line in lines:\n",
        "            # Process the line with the trained NLP model\n",
        "            doc = trained_nlp(line)\n",
        "\n",
        "            # Count the occurrences of each entity label in this line\n",
        "            for ent in doc.ents:\n",
        "                entity_label = ent.label_\n",
        "                entity_counts[entity_label] = entity_counts.get(entity_label, 0) + 1\n",
        "\n",
        "        # Add the counts for this speaker to the main dictionary\n",
        "        speaker_entity_counts[f'{speaker}_{key}'] = entity_counts\n",
        "\n",
        "    return speaker_entity_counts\n",
        "\n",
        "entity_counts_spk1 = count_entity_labels(speakers1_dict, output_dir, \"speaker1\")\n",
        "entity_counts_spk2 = count_entity_labels(speakers2_dict, output_dir, \"speaker2\")\n",
        "print(entity_counts_spk1)\n",
        "print(entity_counts_spk2)\n",
        "\n",
        "# displacy.render(trained_nlp(line), style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cMkPKUJmTwI",
        "outputId": "d00dabd6-a06f-406d-ca70-1f957c8768ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from /content/likers_words\n",
            "Loading from /content/likers_words\n",
            "{'speaker1_4339_6': {'PRODUCT': 2}, 'speaker1_8701_2': {'ORG': 2, 'PRODUCT': 3, 'DATE': 1}, 'speaker1_9230_3': {'ORG': 2, 'DATE': 8, 'PRODUCT': 10}, 'speaker1_4369_1': {'PRODUCT': 17, 'DATE': 8, 'ORG': 1}}\n",
            "{'speaker2_4339_6': {'PRODUCT': 7, 'DATE': 1, 'ORG': 2}, 'speaker2_8701_2': {}, 'speaker2_9230_3': {'DATE': 1, 'PRODUCT': 1}, 'speaker2_4369_1': {'PRODUCT': 2, 'ORG': 2, 'DATE': 7}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_seller_for_each_audio(speaker_dict1:dict, speaker_dict2:dict) -> dict:\n",
        "    # Comparing the labels in speaker_dict1 to speaker_dict2\n",
        "    seller_in_audio = {}\n",
        "\n",
        "    for speaker1, entities1 in speaker_dict1.items():\n",
        "\n",
        "        if len(speaker1.split('_')) > 2:\n",
        "          index = '_'.join(speaker1.split('_')[1:])\n",
        "        else:\n",
        "          index = speaker1.split('_')[1]\n",
        "\n",
        "        entity_comparission = {'speaker1':0, 'speaker2':0}\n",
        "\n",
        "        for entity1, count1 in entities1.items():\n",
        "            if entity1 in speaker_dict2[f'speaker2_{index}']:\n",
        "                if count1 > speaker_dict2[f'speaker2_{index}'][entity1]:\n",
        "                    entity_comparission['speaker1'] += 1\n",
        "                elif count1 < speaker_dict2[f'speaker2_{index}'][entity1]:\n",
        "                    entity_comparission['speaker2'] += 1\n",
        "                else:\n",
        "                    entity_comparission['speaker1'] += 1\n",
        "                    entity_comparission['speaker2'] += 1\n",
        "            else:\n",
        "                entity_comparission['speaker1'] += 1\n",
        "\n",
        "        for entity2, count2 in speaker_dict2[f'speaker2_{index}'].items():\n",
        "            if entity2 not in entities1:\n",
        "                entity_comparission['speaker2'] += 1\n",
        "        # Save the index of the audio and the seller, which is the one that has the greater number in entities\n",
        "        seller_in_audio[index] = 'speaker1' if entity_comparission['speaker1'] > entity_comparission['speaker2'] else 'speaker2'\n",
        "\n",
        "    return seller_in_audio\n",
        "\n",
        "seller_for_each_audio = find_seller_for_each_audio(entity_counts_spk1, entity_counts_spk2)\n",
        "print(seller_for_each_audio)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppHKcFKwtlvb",
        "outputId": "482bafaf-8731-4f1f-a287-7ef95716cfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4339_6': 'speaker2', '8701_2': 'speaker1', '9230_3': 'speaker1', '4369_1': 'speaker1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(speakers1_times)\n",
        "print(speakers2_times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVA_TIhHzGi",
        "outputId": "ea7b70ce-8ba7-4490-cc19-b6fba8926faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4339_6': ['0:00:11 - 0:00:13', '0:00:16 - 0:00:18', '0:00:20 - 0:00:31', '0:00:32 - 0:00:36', '0:00:37 - 0:00:40', '0:00:43 - 0:00:46', '0:00:52 - 0:00:57', '0:00:57 - 0:01:09', '0:01:10 - 0:01:15', '0:01:18 - 0:01:23', '0:01:25 - 0:01:45', '0:01:46 - 0:02:28', '0:02:31 - 0:02:57', '0:02:59 - 0:03:12', '0:03:15 - 0:04:03', '0:04:06 - 0:04:21', '0:04:25 - 0:04:31', '0:04:37 - 0:04:39', '0:04:40 - 0:04:42', '0:04:45 - 0:04:47', '0:04:57 - 0:05:05', '0:05:14 - 0:05:23', '0:05:24 - 0:05:29', '0:05:34 - 0:05:35', '0:05:36 - 0:05:37', '0:05:44 - 0:05:46', '0:05:47 - 0:05:53', '0:05:59 - 0:06:15', '0:06:19 - 0:06:28', '0:06:40 - 0:07:23', '0:07:28 - 0:07:33', '0:07:40 - 0:07:42', '0:07:52 - 0:07:53', '0:07:59 - 0:08:06', '0:08:17 - 0:08:18', '0:08:19 - 0:08:25', '0:08:26 - 0:08:30', '0:08:36 - 0:08:46', '0:08:52 - 0:09:01', '0:09:06 - 0:09:09', '0:09:14 - 0:09:43', '0:09:44 - 0:09:50', '0:09:53 - 0:09:56'], '8701_2': ['0:00:11 - 0:00:13', '0:00:16 - 0:00:18', '0:00:20 - 0:00:31', '0:00:32 - 0:00:36', '0:00:37 - 0:00:40', '0:00:43 - 0:00:46', '0:00:52 - 0:00:57', '0:00:57 - 0:01:09', '0:01:10 - 0:01:15', '0:01:18 - 0:01:23', '0:01:25 - 0:01:45', '0:01:46 - 0:02:28', '0:02:31 - 0:02:57', '0:02:59 - 0:03:12', '0:03:15 - 0:04:03', '0:04:06 - 0:04:21', '0:04:25 - 0:04:31', '0:04:37 - 0:04:39', '0:04:40 - 0:04:42', '0:04:45 - 0:04:47', '0:04:57 - 0:05:05', '0:05:14 - 0:05:23', '0:05:24 - 0:05:29', '0:05:34 - 0:05:35', '0:05:36 - 0:05:37', '0:05:44 - 0:05:46', '0:05:47 - 0:05:53', '0:05:59 - 0:06:15', '0:06:19 - 0:06:28', '0:06:40 - 0:07:23', '0:07:28 - 0:07:33', '0:07:40 - 0:07:42', '0:07:52 - 0:07:53', '0:07:59 - 0:08:06', '0:08:17 - 0:08:18', '0:08:19 - 0:08:25', '0:08:26 - 0:08:30', '0:08:36 - 0:08:46', '0:08:52 - 0:09:01', '0:09:06 - 0:09:09', '0:09:14 - 0:09:43', '0:09:44 - 0:09:50', '0:09:53 - 0:09:56'], '9230_3': ['0:00:11 - 0:00:13', '0:00:16 - 0:00:18', '0:00:20 - 0:00:31', '0:00:32 - 0:00:36', '0:00:37 - 0:00:40', '0:00:43 - 0:00:46', '0:00:52 - 0:00:57', '0:00:57 - 0:01:09', '0:01:10 - 0:01:15', '0:01:18 - 0:01:23', '0:01:25 - 0:01:45', '0:01:46 - 0:02:28', '0:02:31 - 0:02:57', '0:02:59 - 0:03:12', '0:03:15 - 0:04:03', '0:04:06 - 0:04:21', '0:04:25 - 0:04:31', '0:04:37 - 0:04:39', '0:04:40 - 0:04:42', '0:04:45 - 0:04:47', '0:04:57 - 0:05:05', '0:05:14 - 0:05:23', '0:05:24 - 0:05:29', '0:05:34 - 0:05:35', '0:05:36 - 0:05:37', '0:05:44 - 0:05:46', '0:05:47 - 0:05:53', '0:05:59 - 0:06:15', '0:06:19 - 0:06:28', '0:06:40 - 0:07:23', '0:07:28 - 0:07:33', '0:07:40 - 0:07:42', '0:07:52 - 0:07:53', '0:07:59 - 0:08:06', '0:08:17 - 0:08:18', '0:08:19 - 0:08:25', '0:08:26 - 0:08:30', '0:08:36 - 0:08:46', '0:08:52 - 0:09:01', '0:09:06 - 0:09:09', '0:09:14 - 0:09:43', '0:09:44 - 0:09:50', '0:09:53 - 0:09:56'], '4369_1': ['0:00:11 - 0:00:13', '0:00:16 - 0:00:18', '0:00:20 - 0:00:31', '0:00:32 - 0:00:36', '0:00:37 - 0:00:40', '0:00:43 - 0:00:46', '0:00:52 - 0:00:57', '0:00:57 - 0:01:09', '0:01:10 - 0:01:15', '0:01:18 - 0:01:23', '0:01:25 - 0:01:45', '0:01:46 - 0:02:28', '0:02:31 - 0:02:57', '0:02:59 - 0:03:12', '0:03:15 - 0:04:03', '0:04:06 - 0:04:21', '0:04:25 - 0:04:31', '0:04:37 - 0:04:39', '0:04:40 - 0:04:42', '0:04:45 - 0:04:47', '0:04:57 - 0:05:05', '0:05:14 - 0:05:23', '0:05:24 - 0:05:29', '0:05:34 - 0:05:35', '0:05:36 - 0:05:37', '0:05:44 - 0:05:46', '0:05:47 - 0:05:53', '0:05:59 - 0:06:15', '0:06:19 - 0:06:28', '0:06:40 - 0:07:23', '0:07:28 - 0:07:33', '0:07:40 - 0:07:42', '0:07:52 - 0:07:53', '0:07:59 - 0:08:06', '0:08:17 - 0:08:18', '0:08:19 - 0:08:25', '0:08:26 - 0:08:30', '0:08:36 - 0:08:46', '0:08:52 - 0:09:01', '0:09:06 - 0:09:09', '0:09:14 - 0:09:43', '0:09:44 - 0:09:50', '0:09:53 - 0:09:56']}\n",
            "{'4339_6': ['0:00:10 - 0:00:10', '0:00:14 - 0:00:15', '0:00:19 - 0:00:20', '0:00:32 - 0:00:32', '0:00:37 - 0:00:37', '0:00:41 - 0:00:43', '0:00:47 - 0:00:52', '0:00:57 - 0:00:57', '0:01:16 - 0:01:18', '0:01:23 - 0:01:25', '0:01:45 - 0:01:46', '0:03:13 - 0:03:14', '0:04:03 - 0:04:06', '0:04:22 - 0:04:25', '0:04:34 - 0:04:37', '0:04:39 - 0:04:40', '0:04:45 - 0:04:45', '0:04:48 - 0:04:57', '0:05:07 - 0:05:14', '0:05:23 - 0:05:24', '0:05:31 - 0:05:33', '0:05:35 - 0:05:36', '0:05:40 - 0:05:42', '0:05:46 - 0:05:47', '0:05:54 - 0:05:59', '0:06:15 - 0:06:18', '0:06:33 - 0:06:40', '0:07:24 - 0:07:27', '0:07:33 - 0:07:39', '0:07:43 - 0:07:49', '0:07:53 - 0:07:58', '0:08:06 - 0:08:14', '0:08:18 - 0:08:19', '0:08:26 - 0:08:26', '0:08:30 - 0:08:36', '0:08:46 - 0:08:48', '0:08:49 - 0:08:51', '0:09:01 - 0:09:06', '0:09:10 - 0:09:14', '0:09:43 - 0:09:44', '0:09:51 - 0:09:53', '0:09:57 - 0:09:58'], '8701_2': ['0:00:10 - 0:00:10', '0:00:14 - 0:00:15', '0:00:19 - 0:00:20', '0:00:32 - 0:00:32', '0:00:37 - 0:00:37', '0:00:41 - 0:00:43', '0:00:47 - 0:00:52', '0:00:57 - 0:00:57', '0:01:16 - 0:01:18', '0:01:23 - 0:01:25', '0:01:45 - 0:01:46', '0:03:13 - 0:03:14', '0:04:03 - 0:04:06', '0:04:22 - 0:04:25', '0:04:34 - 0:04:37', '0:04:39 - 0:04:40', '0:04:45 - 0:04:45', '0:04:48 - 0:04:57', '0:05:07 - 0:05:14', '0:05:23 - 0:05:24', '0:05:31 - 0:05:33', '0:05:35 - 0:05:36', '0:05:40 - 0:05:42', '0:05:46 - 0:05:47', '0:05:54 - 0:05:59', '0:06:15 - 0:06:18', '0:06:33 - 0:06:40', '0:07:24 - 0:07:27', '0:07:33 - 0:07:39', '0:07:43 - 0:07:49', '0:07:53 - 0:07:58', '0:08:06 - 0:08:14', '0:08:18 - 0:08:19', '0:08:26 - 0:08:26', '0:08:30 - 0:08:36', '0:08:46 - 0:08:48', '0:08:49 - 0:08:51', '0:09:01 - 0:09:06', '0:09:10 - 0:09:14', '0:09:43 - 0:09:44', '0:09:51 - 0:09:53', '0:09:57 - 0:09:58'], '9230_3': ['0:00:10 - 0:00:10', '0:00:14 - 0:00:15', '0:00:19 - 0:00:20', '0:00:32 - 0:00:32', '0:00:37 - 0:00:37', '0:00:41 - 0:00:43', '0:00:47 - 0:00:52', '0:00:57 - 0:00:57', '0:01:16 - 0:01:18', '0:01:23 - 0:01:25', '0:01:45 - 0:01:46', '0:03:13 - 0:03:14', '0:04:03 - 0:04:06', '0:04:22 - 0:04:25', '0:04:34 - 0:04:37', '0:04:39 - 0:04:40', '0:04:45 - 0:04:45', '0:04:48 - 0:04:57', '0:05:07 - 0:05:14', '0:05:23 - 0:05:24', '0:05:31 - 0:05:33', '0:05:35 - 0:05:36', '0:05:40 - 0:05:42', '0:05:46 - 0:05:47', '0:05:54 - 0:05:59', '0:06:15 - 0:06:18', '0:06:33 - 0:06:40', '0:07:24 - 0:07:27', '0:07:33 - 0:07:39', '0:07:43 - 0:07:49', '0:07:53 - 0:07:58', '0:08:06 - 0:08:14', '0:08:18 - 0:08:19', '0:08:26 - 0:08:26', '0:08:30 - 0:08:36', '0:08:46 - 0:08:48', '0:08:49 - 0:08:51', '0:09:01 - 0:09:06', '0:09:10 - 0:09:14', '0:09:43 - 0:09:44', '0:09:51 - 0:09:53', '0:09:57 - 0:09:58'], '4369_1': ['0:00:10 - 0:00:10', '0:00:14 - 0:00:15', '0:00:19 - 0:00:20', '0:00:32 - 0:00:32', '0:00:37 - 0:00:37', '0:00:41 - 0:00:43', '0:00:47 - 0:00:52', '0:00:57 - 0:00:57', '0:01:16 - 0:01:18', '0:01:23 - 0:01:25', '0:01:45 - 0:01:46', '0:03:13 - 0:03:14', '0:04:03 - 0:04:06', '0:04:22 - 0:04:25', '0:04:34 - 0:04:37', '0:04:39 - 0:04:40', '0:04:45 - 0:04:45', '0:04:48 - 0:04:57', '0:05:07 - 0:05:14', '0:05:23 - 0:05:24', '0:05:31 - 0:05:33', '0:05:35 - 0:05:36', '0:05:40 - 0:05:42', '0:05:46 - 0:05:47', '0:05:54 - 0:05:59', '0:06:15 - 0:06:18', '0:06:33 - 0:06:40', '0:07:24 - 0:07:27', '0:07:33 - 0:07:39', '0:07:43 - 0:07:49', '0:07:53 - 0:07:58', '0:08:06 - 0:08:14', '0:08:18 - 0:08:19', '0:08:26 - 0:08:26', '0:08:30 - 0:08:36', '0:08:46 - 0:08:48', '0:08:49 - 0:08:51', '0:09:01 - 0:09:06', '0:09:10 - 0:09:14', '0:09:43 - 0:09:44', '0:09:51 - 0:09:53', '0:09:57 - 0:09:58']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile # to read and write audio files\n",
        "import re\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Function to convert time string to seconds\n",
        "def time_to_seconds(time_str):\n",
        "    parts = list(map(int, re.split('[:]', time_str)))\n",
        "    return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
        "\n",
        "def PlayAudioSegment(filepath, start, end, channel='none'):\n",
        "\n",
        "    # get sample rate and audio data\n",
        "    sample_rate, audio_data = wavfile.read(filepath) # where filepath = 'directory/audio.wav'\n",
        "\n",
        "    #get length in minutes of audio file\n",
        "    print('duration: ', audio_data.shape[0] / sample_rate / 60,'min')\n",
        "\n",
        "    ## splice the audio with prefered start and end times\n",
        "    spliced_audio = audio_data[start * sample_rate : end * sample_rate, :]\n",
        "\n",
        "    ## choose left or right channel if preferred (0 or 1 for left and right, respectively; or leave as a string to keep as stereo)\n",
        "    spliced_audio = spliced_audio[:,channel] if type(channel)==int else spliced_audio\n",
        "\n",
        "    ## playback natively with IPython; shape needs to be (nChannel,nSamples)\n",
        "    return IPython.display.Audio(spliced_audio.T, rate=sample_rate)\n",
        "\n",
        "def play_first_interval(timestamp:dict, key):\n",
        "  first_interval = timestamp[key][0]\n",
        "  start, end = map(time_to_seconds, re.split('[-]', first_interval))\n",
        "  duration = end - start\n",
        "  print(f\"Playing the first interval of key '{key}'...\")\n",
        "\n",
        "\n",
        "  # Get audio file with dict key\n",
        "\n",
        "  base = os.path.abspath('')\n",
        "  file_paths_wav = glob(f\"{base}/*.WAV\")\n",
        "  input_files_wav = [os.path.basename(file_path) for file_path in file_paths_wav]\n",
        "  for wav in input_files_wav:\n",
        "    command = f\"ffmpeg -y -i {wav} -acodec {codec} -ar 44100 dummy.wav\"\n",
        "    os.system(command)\n",
        "    if wav.endswith(f\"{key}.WAV\"):\n",
        "      PlayAudioSegment(\"dummy.wav\", start, end, channel='none')\n",
        "\n",
        "\n",
        "play_first_interval(speakers2_times,'4339_6')\n",
        "play_first_interval(speakers1_times,'8701_2')\n",
        "play_first_interval(speakers1_times,'9230_3')\n",
        "play_first_interval(speakers1_times,'4369_1')\n"
      ],
      "metadata": {
        "id": "isiBDphnCkm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}